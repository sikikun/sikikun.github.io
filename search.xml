<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>服务器jupyternotebook</title>
      <link href="/%E6%9C%8D%E5%8A%A1%E5%99%A8jupyter_notebook%E9%85%8D%E7%BD%AE.html"/>
      <url>/%E6%9C%8D%E5%8A%A1%E5%99%A8jupyter_notebook%E9%85%8D%E7%BD%AE.html</url>
      
        <content type="html"><![CDATA[<!-- build time:Fri Jan 01 2021 21:45:28 GMT+0800 (GMT+08:00) --><a id="more"></a><h1 id="服务器jupyter-notebook配置"><a href="#服务器jupyter-notebook配置" class="headerlink" title="服务器jupyter_notebook配置"></a>服务器jupyter_notebook配置</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>anaconda安装，<code>/home/user</code>使用bash安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash /mnt/sharedisk/xxx/Anaconda3-5.3.1-Linux-x86_64.sh</span><br></pre></td></tr></table></figure><p>注意这里安装完后环境变量问题，可以放到<code>/home/user/.bash</code>添加相应脚本</p><h2 id="jupyter服务启动"><a href="#jupyter服务启动" class="headerlink" title="jupyter服务启动"></a>jupyter服务启动</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ../jupyternotebook/ <span class="comment"># 希望服务启动的文件夹</span></span><br><span class="line">/home/user/anaconda3/bin/jupyter-notebook</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8890/?token=xxxxxxxxxxxxx</span><br></pre></td></tr></table></figure><p>服务启动在对应端口，后面的token需要copy下来</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -p sshport user@ip -L localhost:1234:localhost:8890</span><br></pre></td></tr></table></figure><p>通过ssh访问主机然后将端口代理到<code>localhost:1234</code></p><p>此时本地访问<code>localhost:1234</code>会提示输入token，输入即可进入notebook。</p><h2 id="jupyter内核改变"><a href="#jupyter内核改变" class="headerlink" title="jupyter内核改变"></a>jupyter内核改变</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">conda activate env</span><br><span class="line">conda install ipykernel</span><br><span class="line"></span><br><span class="line">python -m ipykernel install --user --name [虚拟环境名] --display-name <span class="string">"kernel命名"</span></span><br></pre></td></tr></table></figure><p>然后在notebook的 kernel中就可以更改了</p><!-- rebuild by neat -->]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RMIN</title>
      <link href="/RMIN.html"/>
      <url>/RMIN.html</url>
      
        <content type="html"><![CDATA[<!-- build time:Fri Jan 01 2021 21:45:28 GMT+0800 (GMT+08:00) --><blockquote class="blockquote-center"><p>Interactive Trajectory Prediction for Autonomous Driving via Recurrent Meta Induction Neural Network</p></blockquote><a id="more"></a><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>交互式驾驶需要理解并预测周围所有相邻车辆的未来轨迹；目前的方案都是假设一个特定的分布或者随机过程来模仿人类驾驶行为，为放宽这一假设，文章提出RMIN框架。<br>由于随机过程的置换不变性要求，原始的条件神经过程不考虑条件序列，但是序列信息又非常重要。文章用一个递归神经细胞代替原来的演示子网。<br>行为评估以相关车辆的历史观察为条件，从而解决拥挤交通区域的目标车辆换道轨迹。<br>使用元学习框架，使用更小的数据集，需要自动驾驶收集数据更少。</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>换道/匝道合并预测的难点：</p><ol><li>对周围车辆相互作用建模</li><li>基于交互预测连续轨迹</li><li>复杂场景和交互作用，传统学习方法缺乏足够数据<br>本文提出的模型解决上述问题，RMIN基于交互模型捕获相互信息和序列信息。<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><img src="https://i.niupic.com/images/2020/08/14/8wk5.png" alt=""><br>绿色部分是观测者子网；LSTM使用异步设置(Xi包含i时间interval前所有轨迹，Yi是i+1 interval的轨迹)，不获得足够的实例不输出。输出连接FCN获得r：中间条件向量，然后和Xhat一块输入g输出Yhat。<h3 id="Meta-Induction-Program"><a href="#Meta-Induction-Program" class="headerlink" title="Meta Induction Program"></a>Meta Induction Program</h3>Meta Induction Program和普通深度学习方法区别是，不同于直接找新观测的输入和对应输出的映射关系，演示部分编码一种更高task的之前条件更高级的表示。<br>原先方法寻找P(Yhat|Xhat)，而MIP使用一种更多的条件D(示范实例)寻找P(Yhat|Xhat,D)。<br>变道问题看一看做一系列轨迹预测task，每个task周围车辆数量、动态变化类型都不同。网络和示范实例D用来在训练过程中概括task，在评估阶段则用短期的过去轨迹结合先前的观测实例D来对新task进行“分类”。<h3 id="Conditional-Neural-Process"><a href="#Conditional-Neural-Process" class="headerlink" title="Conditional Neural Process"></a>Conditional Neural Process</h3>一种最新的Meta-learning induction methods。在CNP中有三个子模块<br><img src="https://i.niupic.com/images/2020/08/14/8wk1.png" alt=""><br>h是表示网络，可以看做对示范实例输入的编码器；g是生成器网络，可以看做解码器。通过示范网络，生成一组中间结果ri；随着最新的演示，结果r聚合ri用于产生随机过程的因子分解参数。<h3 id="Recurrent-Meta-Induction-Network"><a href="#Recurrent-Meta-Induction-Network" class="headerlink" title="Recurrent Meta Induction Network"></a>Recurrent Meta Induction Network</h3>原始CNP简单聚合是为了满足随机过程的置换不变性，故r的聚合采取均值方法。为了保留序列信息，所以引入一个异步LSTM网络；即原始均值表达被一个LSTM网络和FCN层代替。<br><img src="https://i.niupic.com/images/2020/08/14/8wlg.png" alt=""></li></ol><!-- rebuild by neat -->]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> paper </tag>
            
            <tag> Lane change </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Self-Adaptive Visual Navigation</title>
      <link href="/Self-Adaptive%20Visual%20Navigation.html"/>
      <url>/Self-Adaptive%20Visual%20Navigation.html</url>
      
        <content type="html"><![CDATA[<!-- build time:Fri Jan 01 2021 21:45:28 GMT+0800 (GMT+08:00) --><blockquote class="blockquote-center"><p>Learning to Learn How to Learn: Self-Adaptive Visual Navigation using Meta-Learning</p></blockquote><a id="more"></a><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>训练和推断不分开是人类学习的特点，机器学习冻结模型效率低。导航的一个基本挑战是泛化为看不见的场景，本文提出self-adaptive visual navigation method，可以在没有显式监督前提下学会适应新环境。元强化学习方法，代理学习自我监督有效导航的交互损失。</p><h2 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h2><p>解决方法基于梯度的元学习算法启发。在本方法中使用少量自我监督交互来快速学习，在视觉导航中可以无需使用任何奖励函数或正面实例就可以自适应。在agent训练过程中，它学习一个自监督损失以鼓励有效导航，在训练过程中鼓励让自监督损失引起的梯度和监督导航损失相似。总之其agent是在训练和测试的过程中一边执行导航一边修改其网络的，而不同于传统的强化学习即网络训练后被冻结，也与有监督的元学习不同，因为在新的环境适应过程中没有获得奖励。</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="模型综述"><a href="#模型综述" class="headerlink" title="模型综述"></a>模型综述</h3><p><img src="https://i.niupic.com/images/2020/08/14/8wew.png" alt=""><br>网络有两个优化函数；Lint：自监督交互损失，Lnav：导航损失。网络每个时刻t的输入为当前位置的本身位置图像和目标对象类的词嵌入。网络输出policy π。训练过程中交互、导航梯度通过网络反向传播，在每个episode末尾用导航梯度Lnav来更新自监督损失Lint的参数。在测试阶段，Lint保持不变，模型剩余部分则通过交互梯度进行更新。</p><h3 id="Task定义"><a href="#Task定义" class="headerlink" title="Task定义"></a>Task定义</h3><p>给出目标类，仅通过视觉导航到该类的一个对象。对给定场景、目标类、初始位置为一个task/episode。在每个时间t内，agent从操作集中取出一个操作，直到发出终止操作位置。如果一定数量步骤内agent和给定目标类对象足够接近且可见，则成功；否则则失败。</p><h3 id="Learning"><a href="#Learning" class="headerlink" title="Learning"></a>Learning</h3><p>首先介绍基本模型和传统意义的强化学习。<br>给定自我中心的RGB图像和目标对象类，网络(参数化θ)返回行动的分布π和一个标量v；分布π称为<em>policy</em>而v是状态的<em>值</em>；最后使用π(a)代表agent选择行动a的概率。<br>文章使用一个传统监督Actor-Critic导航损失Lnav，并通过最小化Lnav，最大化一个奖励函数。这个损失是一个episode中一个agent的policies、values、actions、rewards的函数。<br>网络结构如模型图，先使用ResNet18(ImageNet上预训练)然后得到图像和目标信息的联合feature-map，然后进行逐点卷积降维；输出展平再作为一个LSTM网络的输入。再通过一个额外的线性层来获得policy和value。</p><h3 id="Learning-to-Learn"><a href="#Learning-to-Learn" class="headerlink" title="Learning to Learn"></a>Learning to Learn</h3><p>在视觉导航中，agent有充足的机会去和环境交互来学习适应；比如代理可以学习如何处理最初无法绕过的障碍。本文提出了一种方法让代理学会从交互中适应。方法的基础是基于梯度的元学习方法。<br>文章借助了MAML算法，当训练和测试task分布充分类似时，MAML可以快速适应测试任务。<br><img src="https://i.niupic.com/images/2020/08/14/8weV.png" alt=""><br>学习参数θ从而让测试task的快速适应有一个好的初始化。在推理阶段，不使用网络参数θ而使用适应后参数<br><img src="https://i.niupic.com/images/2020/08/14/8wf0.png" alt=""><br>文章目标是在agent和环境交互时不断学习，在MAML中，使用SGD进行这一适应更新。当代理和场景交互时，SGD更新会修改agent的policy网络，从而让它更加适应场景。文章用Lint即交互损失来表示这些更新。最小化这一损失可以帮助代理完成导航任务——这一损失可以学习或者手工指定。为了在推理阶段也能使用Lint，文章使用了自监督损失。<br>我们的目标是通过之前task学到一个好的初始化网络参数，使agent通过Lint的几次梯度更新后在新的环境进行有效导航。<br>对照来说，文章工作使用的损失函数对标于MAML损失函数：<br><img src="https://i.niupic.com/images/2020/08/14/8wf8.png" alt=""><br>使用一阶泰勒展开后方程表示为：<br><img src="https://i.niupic.com/images/2020/08/14/8wfc.png" alt=""><br>损失函数表达如何在最大化自监督交互/自监督导航损失相似度的同时最小化导航损失。如果两个损失非常接近，那么在推理阶段我们不使用Lnav也可以继续训练。然而，对选择梯度相似的Lint是非常困难的，所以我们需要去学习自监督交互损失。</p><h3 id="Learning-to-Learn-How-to-Learn"><a href="#Learning-to-Learn-How-to-Learn" class="headerlink" title="Learning to Learn How to Learn"></a>Learning to Learn How to Learn</h3><p>进一步，将Lint作为被φ参数化的神经网络，当推理时将参数φ保持不变，而没有学到损失的显式目标。这种情况在自监督损失和导航损失接近时可以使新的导航更有效率，我们使用了一维时间卷积来实现。<br>在前面我们已经隐含地将轨迹分解为交互和导航部分，实践中，每k步执行一次自监督交互损失的SGD更新，利用前k步轨迹信息来计算t时刻交互损失；最后用整段导航轨迹计算Lnav。<br><img src="https://i.niupic.com/images/2020/08/14/8wfe.png" alt=""><br><img src="https://i.niupic.com/images/2020/08/14/8wff.png" alt=""><br>很复杂？核心的点就在于我们通过MAML类似方法让Lnav和Lint尽可能相似，然后在Training阶段更新网络权重和Lint的权重，在Testing阶段更新网络权重冻结Lint权重，从而达到自监督边推断边学的目标。</p><!-- rebuild by neat -->]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> paper </tag>
            
            <tag> Visual Navigation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>STML-Traffic Prediction</title>
      <link href="/STML-traffic%20Prediction.html"/>
      <url>/STML-traffic%20Prediction.html</url>
      
        <content type="html"><![CDATA[<!-- build time:Fri Jan 01 2021 21:45:28 GMT+0800 (GMT+08:00) --><blockquote class="blockquote-center"><p>Spatio-Temporal Meta Learning for Urban Traffic Prediction</p></blockquote><a id="more"></a><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>Traffic Prediction：时空关联性复杂/时空关联性和位置相关，取决于周围的地理信息/和时间相关，受动态交通状况影响。<br>提出深度元学习模型：ST-MetaNet+，encoder和decoder具有同样网络结构，由元图注意网络/元递归神经网络组成，分别捕获空间、时间相关性。进一步，元图注意网/元递归神经网络的权重分别来自于地理图属性的embedding和动态交通状态的traffic context。<br>Complex composition of ST correlations/Spatial diversity of ST correlations/Temporal diversity of ST correlations<br><img src="https://note.youdao.com/yws/public/resource/ecd255e5ab7a7c709cb602d36015f534/xmlnote/5A932B507E654AEE900E0C1EF426DFD4/43" alt=""><br><img src="https://note.youdao.com/yws/public/resource/ecd255e5ab7a7c709cb602d36015f534/xmlnote/69ADF25812764ECFB46F5375007D53D9/45" alt=""><br><img src="https://note.youdao.com/yws/public/resource/ecd255e5ab7a7c709cb602d36015f534/xmlnote/2F6755DEC53E4BA2BEDA2116D0DFCA9E/44" alt=""><br>ST-MetaNet+:将地理图属性和动态交通状态作为ST神经网络的元数据来捕捉ST相关性。本文使用基于权值生成的元学习方法。<br><img src="https://i.niupic.com/images/2020/08/13/8w9O.png" alt=""><br>边缘特征：道路连通性、节点间距离etc。节点特征:GPS位置、附近POI分布等。交通状态则隐含了交通上下文的信息。ST-MetaNet+首先从nodes和edges中分别提取元知识，并从流量状态中提取出动态traffic context；然后将提出的信息使用一个信息融合模块随后用来对ST相关性建模——即生成时空模型的权重。<br>使用Meta-GAT+建模空间相关性；attention机制捕捉位置间关于当前状态的相互关系；此外由地理图属性中提取结点、边的元知识，结合交通状态中的动态交通上下文生成图注意力的网络权重。提出Meta-GRU+，通过每个结点的元知识和traffic context生成所有递归门单元的权重；因此在不同交通状态下，每个位置都有其自己类型的时间相关性唯一模型。</p><h2 id="模型具体"><a href="#模型具体" class="headerlink" title="模型具体"></a>模型具体</h2><p><img src="https://i.niupic.com/images/2020/08/13/8waf.png" alt=""><br>蓝色编码器，绿色解码器。编码解码器具有相同网络结构，包括三种组件：</p><ol><li>Meta-knowledge learner：使用两个全连接网络FCN分别从结点属性和边缘属性中学习元知识。其中边元知识学习器EMK，结点元知识学习器NMK，两者结合称为MK；如：一个特定结点属性输入到NMK学习器输出一个向量，代表这个结点的元知识。</li><li>Meta-GAT+：context learner/通过FCN学习traffic context；fusion gate/将点边的元知识和学习到的traffic context结合起来/使用一个FCN作为元学习器从而得到GAT的参数权重。Meta-GAT+通过结点沿边的隐状态虚线单向广播获得不同的空间相关性。</li><li>Meta-RNN+：和2类似，GAT由RNN代替，只获取结点元知识。Meta-RNN+通过结点地理信息和动态交通状态获取不同时间相关性。<h3 id="Meta-knowledge-learner"><a href="#Meta-knowledge-learner" class="headerlink" title="Meta-knowledge learner"></a>Meta-knowledge learner</h3>输入结点、边的属性，输出对应embedding后的向量；接下来再作为GAT或者RNN的输入。<h3 id="Meta-Graph-Attention-Network"><a href="#Meta-Graph-Attention-Network" class="headerlink" title="Meta Graph Attention Network+"></a>Meta Graph Attention Network+</h3><img src="https://i.niupic.com/images/2020/08/13/8wbx.png" alt=""></li></ol><ul><li>attention捕获不同结点的空间关联性</li><li>权重来源于meta learner，信息来源于点、边元知识和traffic context，所以边和点空间相关性建模应用的注意力机制是不一样的，取决于地理信息和动态交通状态。</li><li>输入为交通状态 H 和geo-graph G 。</li><li>每个节点的元图注意力机制包含两步：对每个边的注意力分数计算、隐状态整合。<h3 id="注意力分数计算"><a href="#注意力分数计算" class="headerlink" title="注意力分数计算"></a>注意力分数计算</h3>基于处理后的交通状态和geo-graph的元知识。边(i,j)的注意力分数来源于结点i/j的隐状态，从地理信息学到的边、点元知识和这些结点的traffic context。<br>如图，MK(ij)=NMK(v(i))||NMK(v(j))||EMK(e(ij)),其中||是向量连接操作。<br>TC(traffic context)利用隐状态作为输入<br><img src="https://i.niupic.com/images/2020/08/13/8wbI.png" alt=""><br>设置CL维度使TC和MK输出维度一样。<br><img src="https://i.niupic.com/images/2020/08/13/8wbK.png" alt=""><br>利用这些向量和隐状态表示h’(j)对h’(i)每个通道影响的大小w(ij)，计算话术a(-)采用了一个全连接层。因为不同节点对有不同元知识和动态TC，所以注意力机制也不一样。<br>而这里的W(ij)即权重矩阵是来源于融合信息(FI)——MK和FC，受LSTM启发，采用了融合门(fusion gate)来计算融合信息:<br><img src="https://i.niupic.com/images/2020/08/13/8wcg.png" alt=""><br>获得FI(ij)，通过Meta learner,两个所有边共享权重的FCN:g(w)g(b)分别生成W(ij)和b(ij)<h3 id="隐状态聚合"><a href="#隐状态聚合" class="headerlink" title="隐状态聚合"></a>隐状态聚合</h3>通过softmax计算注意力分数：<br><img src="https://i.niupic.com/images/2020/08/13/8wcF.png" alt=""><br>然后对每个结点，按照上述权重计算所有邻居的隐状态影响，为了好训练再加入shortcut连接，最终输出结点i考虑到空间相关性的隐状态：<br><img src="https://i.niupic.com/images/2020/08/13/8wcJ.png" alt=""><h3 id="Meta-Recurrent-Network"><a href="#Meta-Recurrent-Network" class="headerlink" title="Meta Recurrent Network+"></a>Meta Recurrent Network+</h3>类似Meta-GAT+，从结点属性和动态TC获得RNN网络权重。<br><img src="https://i.niupic.com/images/2020/08/13/8wcP.png" alt=""><h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3>普通神经网络参数w1直接链式规则计算。元知识学习器、context learner、meta learners的参数w2即那些产生GATs和RNNs网络中参数的网络也可以通过链式规则计算。<br><img src="https://i.niupic.com/images/2020/08/13/8wcR.png" alt=""></li></ul><!-- rebuild by neat -->]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> paper </tag>
            
            <tag> Traffic Prediction </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IDL</title>
      <link href="/IDL.html"/>
      <url>/IDL.html</url>
      
        <content type="html"><![CDATA[<!-- build time:Fri Jan 01 2021 21:45:28 GMT+0800 (GMT+08:00) --><blockquote class="blockquote-center"><p>Which Way Are You Going? Imitative Decision Learning for Path Forecasting in Dynamic Scenes</p></blockquote><a id="more"></a><h2 id="文章摘要"><a href="#文章摘要" class="headerlink" title="文章摘要"></a>文章摘要</h2><ul><li>提出Imitative Decision Learning，挖掘多模态的本质特征：隐变量决策（latent decision）</li><li>IDL首先通过移动历史推断latent decision的分布；然后考虑采样的隐变量决策生成一种方针（policy），来预测未来轨迹。对于每种采样的隐决策，生成不同的可行未来轨迹。</li><li>现有的方法都是预定义的隐变量。</li><li>为了进一步增强latent decision和合成的多模态的理解，通过相互信息优化（mutual information optimization）来探索它们间的联系。</li><li>将时空相关性整合进一个单独的框架而不是两步，可以同时处理场景内所有的行人。</li></ul><h2 id="图说"><a href="#图说" class="headerlink" title="图说"></a>图说</h2><p>Figure 1. 在动态场景中，过去移动轨迹相同，未来的可行路径也会有很多种。<br>Figure 2. IDL的原理图。<br><img src="https://i.niupic.com/images/2020/08/07/8v7p.png" alt=""><br>红色箭头代表模块间信息流向，黑色箭头是一个模块内的信息流动。<br>Figure 3. ADE/FDE在SAP数据集上比较（best）。<br>Figure 4. 在SAP上的定性比较。<br>Table 1. 定量比较。<br>Figure 5. ETH数据集上的定性比较。</p><h2 id="不足及改进思路"><a href="#不足及改进思路" class="headerlink" title="不足及改进思路"></a>不足及改进思路</h2><p>spatial dependencies（人人之间交互）temporal dependencies（不断进展的运动模式）</p><h3 id="隐变量"><a href="#隐变量" class="headerlink" title="隐变量"></a>隐变量</h3><p>目前的工作尝试将多模态问题解释为基于预定义的隐变量z~N(0,1)<br>Latent decision：人潜在的决策潜在的确定了未来的运动模式，进而勾勒出轨迹。<br><strong>Key insight：人行动的轨迹是其decision的结果，而decision取决于动态场景内所有的相关元素（spatial/temporal dependencies）</strong><br>这便解释了未来多可行路线的原因：人行走过程中有多种decision。<br>IDL基于GAIL的观点；具体来说，先从历史观测中推断出与latent decision对应的分布（包含了大量人类决策信息），然后生成policy；通过优化它们的相互信息来进一步增强policy和latent decision的联系；这种优化突出了latent decision在多模态轨迹中的内在影响。需要注意的是latent decision以无监督方式进行学习。</p><h3 id="时空依赖性"><a href="#时空依赖性" class="headerlink" title="时空依赖性"></a>时空依赖性</h3><p>之前工作将时间、空间依赖分开处理；对于每个行人使用LSTM获取temporal信息，随后使用一个社会池化项获取空间信息；这些方法忽略了时间空间信息是同时发生而且会互相影响的事实————它们最好结合起来整合进同一个模型中。<br>本文工作将时空信息整合，而且可以同时预测动态场景中所有行人的轨迹。</p><h3 id="延伸阅读"><a href="#延伸阅读" class="headerlink" title="延伸阅读"></a>延伸阅读</h3><p><strong>GAIL</strong>Jonathan Ho and Stefano Ermon. <em>Generative adversarial imitation learning.</em> In Advances in Neural Information Processing Systems, pages 4565–4573, 2016.<br><a href="https://blog.csdn.net/jinzhuojun/article/details/85220327" target="_blank" rel="noopener">https://blog.csdn.net/jinzhuojun/article/details/85220327</a><br>Mohamed Ishmael Belghazi, Aristide Baratin, Sai Rajeshwar, Sherjil Ozair, Yoshua Bengio, Aaron Courville, and Devon Hjelm. <em>Mutual Information Neural Estimation</em>. In Proceedings of the 35th International Conference on Machine Learning(ICML), volume 80, pages 531–540, 10–15 Jul 2018.<br>Tian Qi Chen, Xuechen Li, Roger Grosse, and David Duvenaud. <em>Isolating Sources of Disentanglement in Variational Autoencoders</em>. In Advances in Neural Information Processing Systems (NIPS), 2018.</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>工作从GAIL中借用符号表示：<br><img src="https://i.niupic.com/images/2020/08/07/8v8X.png" alt=""><br>分别代表运动历史和未来的ground truth；这些运动特征借由位移信息封装了个体的运动模式。<br>IDL通过对上式第一项即过去轨迹信息中提取中方针（policy）π进而产生下式，即预测未来轨迹。<br><img src="https://i.niupic.com/images/2020/08/07/8v91.png" alt=""><br>我们在生成未来多模态的轨迹藉由在提取policy(π)中合并latent decision(S)。<br>Latent decision未知，需要推断：<br><img src="https://i.niupic.com/images/2020/08/07/8v9b.png" alt=""><br>其中~后面的一项代表S被采样后的分布。<br>相比于GAIL，IDL不仅从Xt中提取policy，还学习S，然后通过无监督的优化π和S之间的互信息来量化S对于预测的影响。</p><h3 id="Imitative-Decision-Learning"><a href="#Imitative-Decision-Learning" class="headerlink" title="Imitative Decision Learning"></a>Imitative Decision Learning</h3><p>IDL可以分为以下几个子部分:</p><ol><li>推断latent decision的推理子网</li><li>生成policy(π)来推断未来路径</li><li>统计子网Q来探索latent decision对于预测的影响</li><li>一个鉴别器D通过专业演示来判别生成结果的不同<h4 id="Latent-Decision-Inference"><a href="#Latent-Decision-Inference" class="headerlink" title="Latent Decision Inference"></a>Latent Decision Inference</h4>全卷积接时间卷积，形成二元矢量；反卷积softmax得到μ和σ，它们是latent decision S的条件高斯分布的采样。使用重新参数化的技巧对latent decison进行了采样。<br><img src="https://pic.downk.cc/item/5f3107ee14195aa59426a13a.png" alt=""><h4 id="Policy-Generator"><a href="#Policy-Generator" class="headerlink" title="Policy/Generator"></a>Policy/Generator</h4>人类决策制定过程具有序列性，所以使用ConvGRU来建立了一个encoder-decoder结构来实现policy(π)。<br><img src="https://pic.downk.cc/item/5f31082914195aa59426b4e7.png" alt=""><br>Conv单层卷积，去除数据稀疏性。<br>单纯编码的隐状态未考虑latent decision；所以将之前获得的Latent decision S与隐状态结合起来（逐元素求和），所以S的每个采样都会产生不同的可行预测。<br>未来部分h(t’)仅和临近的前隐状态有关h(t’-1)；使用单个步长2的反卷积层获得未来轨迹，这个反卷积层是为了让解码层隐状态和输入的大小一样。<br>decoder的隐状态和预先指定的对数标准偏差来形成高斯分布，以用来进行Proximal Policy Optimization(PPO)。<h4 id="Mutual-Information-Optimization"><a href="#Mutual-Information-Optimization" class="headerlink" title="Mutual Information Optimization"></a>Mutual Information Optimization</h4>为了量化latent decision在预测中的意义，使用互信息I(S,π)来进行量化表示。<br><img src="https://pic.downk.cc/item/5f310e6f14195aa59429019f.png" alt=""><br>值越大代表latent decision的影响越大。<br>对它进行优化可以激励S并巩固它对预测的影响，并增强我们对latent decision对于多模态未来路径的语义理解。<br>借助Mutual Information Neural Estimator的帮助，优化互信息等同于最大化其下界L(I),所以我们引入了一个统计子网Q<br><img src="https://pic.downk.cc/item/5f310fc414195aa594298424.png" alt=""><br>上式S和Shat是p(S|Xt)的独立同分布。<br>最后的LI是通过将预测轨迹、S的联合起来通过全连接层获得；它们分别来源于时间卷积和全卷积模块。<h4 id="Discriminator-and-Objective"><a href="#Discriminator-and-Objective" class="headerlink" title="Discriminator and Objective"></a>Discriminator and Objective</h4>应用GAIL来训练框架；所以保证了基于梯度学习的效率，也将路径预测问题转换为occupancy measure matching问题。我们使用一个判别器D来区分[Xt,Xt’]和[Xt,GTt’]来指导π，判别器的目标函数如下：<br><img src="https://pic.downk.cc/item/5f3113ee14195aa5942b085d.png" alt=""><br>判别器D由一个个单个CovGRU层组成，在ConvGRU层上方叠加四个卷积堆叠层来获得分数；π从D中通过PPO获得梯度，从而最大化下列目标函数：<br><img src="https://pic.downk.cc/item/5f3114a414195aa5942b43ed.png" alt=""></li></ol><!-- rebuild by neat -->]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> paper </tag>
            
            <tag> predict trajectory </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PLOP</title>
      <link href="/PLOP.html"/>
      <url>/PLOP.html</url>
      
        <content type="html"><![CDATA[<!-- build time:Fri Jan 01 2021 21:45:28 GMT+0800 (GMT+08:00) --><blockquote class="blockquote-center"><p>PLOP: Probabilistic poLynomial Objects trajectory Planning for autonomous driving</p></blockquote><a id="more"></a><hr><h2 id="核心"><a href="#核心" class="headerlink" title="核心"></a>核心</h2><ul><li>解决的问题是无人驾驶车辆（ego-vehicle）和它周围车辆（neighbor vehicle）轨迹分布概率问题。</li><li>其输入不是单一的轨迹，而是过去轨迹、前置摄像头图像、鸟瞰网格结合作为输入。</li><li>预测时使用多项式来表示mean位置，而不是使用LSTM直接预测点位。</li><li>预测时分割为三部分：ego-vehicle的轨迹/neighbor-vehicle的轨迹/辅助语义分割（最后一项训练以提取更多有用信息，并使模型的可解释度更高）</li><li>conf/weight/min,在评价指标上进行了一定创新，考虑多模态预测的置信度问题。</li></ul><h2 id="本文综述"><a href="#本文综述" class="headerlink" title="本文综述"></a>本文综述</h2><p>ego-vehicle在行驶过程中一般有多种选择；本文聚焦于通过一种概率框架来预测ego-vehicle和其邻居的多条可行未来轨迹。这里使用了一种条件模拟学习算法，并以ego-vehicle的导航命令（如右转）作为条件。<br>其输入是ego-car前置摄像头的图像，鸟瞰视角网格及表示的雷达点云，过去的目标过去探测；输出ego-vehicle和邻居的可能轨迹，并进行语义分隔作为辅助损失。</p><hr><h2 id="图说"><a href="#图说" class="headerlink" title="图说"></a>图说</h2><p>Figure 1. nuScenes上的定性示例。PLOP输入图像和雷达点云及车辆2s的过去轨迹来实施未来4s的轨迹计划。它通过概率Gaussian Mixture models（受多项式公式约束）来处理不确定性和可变性。<br>Figure 2. 输入的鸟瞰视图：ego-vehicle的坐标系；分隔为单元格，包含相邻车辆位置/状态/类别/雷达点个数；每个鸟瞰视图用一个121×21×5的张量表示。<br>Figure 3. PLOP的神经网络框架。绿色部分是encoder，蓝色是预测部分。<br>Figure 4. 轨迹预测的简化表示模型。K是固定数量的可能轨迹，T是预测的时间步。每个采样的高斯部分被表示为一个椭圆圆心μ和形状σ。<br>Table 1. 与DESIRE-plan，ESP，PRECOG预测结果在minMSD指标上的比较。<br>Figure 5. conf置信最高的轨迹，weight预测的置信加权，min最接近真实的轨迹。x轴代表以米为单位的阈值，y轴代表测试集上FDE小于阈值所占的样本的百分比。<br>Figure 6. 横纵轴的FDE变化，坐标的x-y轴与figure5一样。使用测试集上的ego-vehicle。<br>Table 3. 控制变量在MSD和ADE的指标变化。<br>Figure 7. 预测轨迹条数K类似figure5/6的比较，仅比较minFDE。<br>Table 4. 高斯混合预测的K变化对于MSD和ADE的影响。</p><hr><h2 id="展开"><a href="#展开" class="headerlink" title="展开"></a>展开</h2><h3 id="问题及解决思路"><a href="#问题及解决思路" class="headerlink" title="问题及解决思路"></a>问题及解决思路</h3><p>要到达一个指定的位置，或者实施一个更高级的目标比如保持车道、在十字路口转弯等。<br>场景描述的输入值得考虑，本文使用雷达和前摄像头的传感器数据，并检测附近车辆的轨迹。<br>PLOP解决的是车辆的轨迹规划，分别预测ego-vehicle和neibor vehicle的轨迹，并利用ego的前置摄像头图像来作为辅助损失。<br><strong>本工作是对于离线数据的评估轨迹规划；因为imitation learning对于在线学习效率不够</strong><br>T. Buhet, ´ E. Wirbel, and X. Perrotton, “Conditional vehicle trajectories prediction in carla urban environment,” ArXiv, vol. abs/1909.00792, 2019.本文作者先前工作<br>M. Bansal, A. Krizhevsky, and A. S. Ogale, “Chauffeurnet: Learning to drive by imitating the best and synthesizing the worst,” CoRR, vol.abs/1812.03079, 2018. ChauffeurNet<br>M. Bojarski et al., “End to end learning for self-driving cars,” CoRR, vol. abs/1604.07316, 2016. Nvidia</p><h3 id="PLOP的贡献"><a href="#PLOP的贡献" class="headerlink" title="PLOP的贡献"></a>PLOP的贡献</h3><ul><li>不是使用RNN译码器，而是预测多项式函数的系数来预测轨迹。</li><li>将之前的工作扩展到多输入模式，同时在保持多项式轨迹公式的前提下，将确定性输出升级为多模态概率输出。</li><li>增加了雷达和语义分割辅助损失。</li><li>两个新的标准：最置信误差/置信加权误差<h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><h4 id="输入：过去轨迹-相机-雷达"><a href="#输入：过去轨迹-相机-雷达" class="headerlink" title="输入：过去轨迹/相机/雷达"></a>输入：过去轨迹/相机/雷达</h4></li><li>所有输入的数据都以10Hz进行采样，最大neighbor N=10，过去的输入在2s的时间窗内累积起来</li><li>过去轨迹以时间序列进行表示，包括过去两秒的ego-vehicles和neighbor vehicle；利用前置RGB相机，FOV=70°。</li><li>雷达点云和邻居探查被投影到鸟瞰网格中，如figure2所示；因为是过去2s的累积，所以一共20帧。<br><img src="https://i.niupic.com/images/2020/08/04/8uyd.png" alt=""></li><li>最后作为网络的条件部分，使用导航命令：follow(远离十字路口)；left,straight,right(靠近十字路口)<h4 id="网络结构-1"><a href="#网络结构-1" class="headerlink" title="网络结构"></a>网络结构</h4><img src="https://i.niupic.com/images/2020/08/04/8uyi.png" alt=""><h5 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h5></li><li>使用经典VGG16对ego前摄像头编码</li><li>鸟瞰视图使用三维卷积，再接个小的卷积网络</li><li>最后使用LSTM对轨迹进行编码;注意ego有自己的LSTM权重，neighbors间的LSTM权重是共享的。N值仅在网络图的占位符中有用，不影响网络结构，因为neighbors数不可知。<h5 id="Predictor"><a href="#Predictor" class="headerlink" title="Predictor"></a>Predictor</h5></li><li>引入一个来自于Unet-VGG16的辅助语义分割解码器来学到更多有用特征。</li><li>对于neighbors轨迹预测，对每一辆车将鸟瞰图和考虑车辆的过去轨迹编码连接并经过3个FC输出一个多元高斯混合以输出固定数量的可能轨迹K。</li><li>最后，ego-vehicle的轨迹预测类似neighbors轨迹预测，增加了图像编码部分，并在全连接层增加条件维度。3个FC被4个3层FC代替因为navigatinon命令有四种。<h5 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h5>对于某一个车辆的预测，我们并不能直接访问其他车辆的历史位置，车辆之间的交互由鸟瞰图隐式表达，这允许我们网络中neighbors的数量可以是不可知的。<h4 id="网络输出"><a href="#网络输出" class="headerlink" title="网络输出"></a>网络输出</h4><h5 id="轨迹预测"><a href="#轨迹预测" class="headerlink" title="轨迹预测"></a>轨迹预测</h5>网络主要有两个输出：ego车辆和neighbor车辆未来的轨迹，具体来说我们对每个车辆预测固定数目K条可能轨迹，并将它们在x、y上的概率分布相关联，我们做出以下假设：</li><li>x和y互相独立</li><li>对于ego-vehicle，我们估计了在导航命令c条件下的分布概率。</li><li>分布仅在固定点表示，我们预测4s轨迹，故index即T为0-40。</li><li>对于统一轨迹上的所有采样点，共享混合权重πk。</li><li>分别对于x、y，分布的mean用一个时间的四次多项式表示，且用了下图μ的表达形式，这既减少了参数数量，又保证了轨迹点的动力学限制。</li></ul><p>对于未来的采样点t∈[0,T]，概率密度函数为<br><img src="https://i.niupic.com/images/2020/08/04/8uzc.png" alt=""><br>网络输出的是参数πk和<br><img src="https://i.niupic.com/images/2020/08/04/8uzf.png" alt=""><br>对于ego-vehicle还有命令c<br>最后这种表示可以解释为预测K个轨迹，每个都和置信度πk有关，采样点遵循μx/μy/σx/σy的高斯分布。</p><h5 id="辅助语义分割输出"><a href="#辅助语义分割输出" class="headerlink" title="辅助语义分割输出"></a>辅助语义分割输出</h5><p>语义分割七类：无/车辆/行人/交通信号/车道标线/道路/人行道；这些信息对驾驶有用。<br>这里的目标是确保在RGB图像编码中，关于道路位置和可行性、交通规则和容易被伤害到的道路用户位置等可以被获得。<br>这些信息对于轨迹计划有效，并给模型带来一定可解释性。</p><h5 id="损失"><a href="#损失" class="headerlink" title="损失"></a>损失</h5><p>我们的目标是最小化NLL；为了提升侧向轨迹（更难预测），我们对于y轴的损失增加权重α；x拔y拔代表ground truth；c是当前导航命令。<br><img src="https://i.niupic.com/images/2020/08/05/8uzr.png" alt=""><br>对于辅助语义分割输出，我们使用交叉熵损失。</p><h3 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h3><p>MSD/ADE/FDE<br>文章提出了，多轨迹预测中我们不能使用一条几率低但是很符合ground truth的轨迹；所以引入了confMSD/confADE/confFDE让k选择置信度最高的轨迹；同时也引入了带权重的上述指标（对置信度进行加权求和）同时也保留了minADE等。<br>还有一个很有趣的信息，文章做了一个conf，weight，min指标的对比。可以看出在ego车辆在阈值达到一定水平后minFDE和confFDE/weightFDE的差距变小，而neighbor仍差距大，所以说明运动计划的加入会使不同行为的种类显著减小。<br><img src="https://i.niupic.com/images/2020/08/06/8uV1.png" alt=""></p><!-- rebuild by neat -->]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> paper </tag>
            
            <tag> predict trajectory </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Trajectron++</title>
      <link href="/Trajectron++.html"/>
      <url>/Trajectron++.html</url>
      
        <content type="html"><![CDATA[<!-- build time:Fri Jan 01 2021 21:45:28 GMT+0800 (GMT+08:00) --><blockquote class="blockquote-center"><p>Trajectron++: Dynamically-Feasible Trajectory Forecasting With Heterogeneous Data</p></blockquote><a id="more"></a><h2 id="核心"><a href="#核心" class="headerlink" title="核心"></a>核心</h2><ul><li>针对具有自主行为的agent搭建的通用框架，将场景建模为有向图，点为agent，边为interaction。</li><li>输入中还包含运动计划、未来轨迹，并用ablation study证明了有效性。</li><li>使用CVAE来显式处理表征多模态（这里隐空间问题没有搞懂，需要进一步学习）</li><li>decoder部分考虑动力学因素，将行人和车辆分别建模，满足了一定的动力约束</li></ul><h2 id="本文综述"><a href="#本文综述" class="headerlink" title="本文综述"></a>本文综述</h2><ul><li>现有方法大多数没有使用强制动态约束，没有考虑环境信息（如地图）</li><li>提出Trajectron++，一个模块化、图递归的模型：结合agent动力学和异构数据（如语义地图）；针对于机器人规划和控制框架，可生成选择性的自我运动规划；</li></ul><hr><h2 id="图说"><a href="#图说" class="headerlink" title="图说"></a>图说</h2><p>Figure 1. 描述行人在车辆前方穿过道路的场景。车辆可直行/左转，agent用白色圆圈表示，agent间相互作用用黑色虚线表示。箭头表示未来可能的速度，颜色代表不同的行为模式。<br>Figure 2. 左图：将场景描述为一个有向时空图，结点和边分别代表agent和它们的交互；右图：对于左图结点一对应的网络。<br>Table 1. 输出最可能的数据和确定性方法比较在位移偏差指标上仍然优秀，尽管不是为此而训练的；在概率输出方法全面优于其他方法。<br>Table 2. 每个数据集上平均基于KDE的NLL；每个timestep采样2000个轨迹。<br>Figure 3. 在ETH数据集上：如果只使用轨迹数据，Trajectron++不了解障碍物，会走到墙里；对局部地图进行编码可以有效的减少遇障几率。<br>Table 3. 在nuScenes数据集上：(a)只有车辆的FDE比较 (b)只有行人的FDE和KDE NLL的Trajectron++表现。<br>Table 4. 通过将ego-vehicle包含/排除的方法来验证方法表现提升不会因为仅移除ego-vehicle而提升。<br>Figure 4. 在nuScenes数据集上：表达∫和M的有效性。</p><hr><h2 id="展开"><a href="#展开" class="headerlink" title="展开"></a>展开</h2><h3 id="现有情况"><a href="#现有情况" class="headerlink" title="现有情况"></a>现有情况</h3><p>现有的multi-agent行为预测方法：确定性回归模型/生成概率模型。<br>很多的方法都忽略了<strong>real-world robotic use cases</strong>，比如agent间的动力学约束；ego-agent本身的运动（这对于人-机器人交互中重要部分）；现代机器人系统可以获得的大量的环境信息。实现了这些情况的少数几种方法闭源/绑定特定机器人平台/私人数据。</p><h3 id="Trajectron-的贡献"><a href="#Trajectron-的贡献" class="headerlink" title="Trajectron++的贡献"></a>Trajectron++的贡献</h3><ol><li>如何通过编码语义地图来整合高维数据。</li><li>提出了一种通用的方法，将动力学约束整合进基于学习的multi-agent预测方法中。</li><li>Trajectron++和下游的机器人模块紧密结合，可以有选择的按照ego-agent的运动计划生成轨迹。<h3 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h3></li></ol><ul><li>确定性回归模型：社会力模型；高斯回归过程（GPR）；逆强化学习（IRL）；RNN</li><li>生成/概率性方法：多模态轨迹生成对于下游任务更加有利，方差等信息可以让自治系统做出更安全的决策。变分自动编码器（CVAE）：显式编码多模态，依赖二元高斯混合模型输出位置分布；GAN。</li><li>Trajectron和Social BiGAT分别是基于CVAE和GAN性能最好的模型，但都未考虑动力学模型和异构输入数据；它们的实验中都只有行人agent。</li><li>两者研究方向不同，概率模型的预测平均值是否可以对应于确定轨迹都未可知；基于GAN模型的方法甚至只能采样不能获得任何分布信息。</li><li>标准轨迹预测很少包含除先前轨迹以外的信息；加入其它信息的方法大多使用端到端的学习架构，用CNN对传感器观测值编码再训练来优化多任务目标。这种方法只能在固定的历史信息上运行，因为CNN的权重大小固定。递归框架则可以考虑所有的历史信息；此外这些框架无法捕捉到动态约束。<h3 id="问题表述"><a href="#问题表述" class="headerlink" title="问题表述"></a>问题表述</h3><img src="https://i.niupic.com/images/2020/08/02/8tZG.png" alt=""><br>不同于之前工作中只输入过去和现在的位置，我们希望通过现代机器人传感器套件提供更多异构数据。对每个agent：Ai，我们还假设其周围有一定的语义地图。<br><img src="https://i.niupic.com/images/2020/08/02/8tZB.png" alt=""><br>其中C为context size；r为空间分辨率；L为语义频道数。根据数据集不同，语义可以从简单障碍物到多层语义信息（人行道、路边界等）。<br>一个关键想法是考虑到ego-agent的运动计划，从而便于下游使用。因此，我们会将ego-agent未来的运动计划作为一个条件（未来T个timestep假设已知）。<h3 id="Trajectron"><a href="#Trajectron" class="headerlink" title="Trajectron++"></a>Trajectron++</h3><img src="https://i.niupic.com/images/2020/08/02/8tZX.png" alt=""><br>在高层次上，问题场景的时空图是由其拓扑结构创建的，然后生成一个类似结构的深度学习结构，预测结点属性的变化，从而生成agent轨迹。<h4 id="场景表示"><a href="#场景表示" class="headerlink" title="场景表示"></a>场景表示</h4>场景抽象为图G=（V,E），结点代表agent，边代表它们间的交互作用。每个结点都有一个语义类（汽车，巴士，行人），两个结点间有边证明他们的代理可以互相影响，在这项工作中使用l2距离代表两个agent是否互相影响(即存不存在边)-计算开销小：<br><img src="https://i.niupic.com/images/2020/08/02/8tZR.png" alt=""><br>这种方法泛用性较好；将场景建模为有向图，因为有向图可以表达更一般的场景集合交互类型。（比如汽车驾驶员在道路上的视线比行人眼光更远）<h4 id="Agent历史建模"><a href="#Agent历史建模" class="headerlink" title="Agent历史建模"></a>Agent历史建模</h4>构建完场景图后，对一个节点的当前、历史和周围节点对它的影响进行编码，遂使用32维的LSTM网络，并输入其当前和之前的状态，输入的状态是之前H时间步的结点状态，D维状态典型包括位置和速度等。<br>理想情况下，agent模型和它们的语义类应该比较好的符合，但从在线观测中估计另一辆车的各种参数是非常困难的。因此在这篇文章的工作中，行人被建立为单一的integrator，带轮的车辆被建模为dynamically-extended unicycles，这就可以让我们考虑一些关键的非完整约束（如无侧滑约束），而不需要复杂的在线参数估计步骤。如果能快速估计其他的参数，方法可以推广到其他动力学模型。<h4 id="编码Agent交互"><a href="#编码Agent交互" class="headerlink" title="编码Agent交互"></a>编码Agent交互</h4>说明周围agent对建模agent的影响，Trajectron++将图边分两步进行编码。</li></ul><ol><li>从邻近同一语义类别的agent聚合边信息，本工作中是使用element-wise sum作为聚合操作。然后这些聚集状态输入到一个8维LSTM；这些权重在同类型的边（如行人-巴士边）中共享。</li><li>与建模结点项链的所有边类型的编码聚合起来获得一个“influence”代表向量，代表所有邻居结点的影响。这里使用了一个额外的注意力模块。<br>最后，结点历史和边影响编码连接起来以生成一个单一的结点表示向量ex。<h4 id="整合异构数据"><a href="#整合异构数据" class="headerlink" title="整合异构数据"></a>整合异构数据</h4>根据传感器可用和复杂程度，我们可以从简单的0-1障碍地图到高清的语义地图<br><img src="https://i.niupic.com/images/2020/08/02/8u0c.png" alt=""><br>Trajectron++使用CNN进行了一个局部地图编码来利用这些信息。CNN有四层{5，5，5，3}，步数分别是{2，2，1，1}然后接一个32维全连接，输出和历史、边交互信息再连接，生成向量ex。<h4 id="编码Ego-Agent的未来行动计划"><a href="#编码Ego-Agent的未来行动计划" class="headerlink" title="编码Ego-Agent的未来行动计划"></a>编码Ego-Agent的未来行动计划</h4>对一组运动原语进行关于其他agent可能回应的评估。Trajectron++使用32维双向LSTM来编码未来T时间步的ego-agent的运动计划yR。最后的隐状态连接在代表向量ex的主干中。<h4 id="对多模态的显式解释"><a href="#对多模态的显式解释" class="headerlink" title="对多模态的显式解释"></a>对多模态的显式解释</h4>Trajectron++通过利用CVAE隐变量框架来显式处理多模态。<br><img src="https://i.niupic.com/images/2020/08/02/8u0n.png" alt=""><br>|Z|=25，φ和θ是NN的权重，是它们各自分布的参数化。z的离散化也有利于通过采样轨迹来可视化哪些高级行为属于哪个z。<br>训练过程中，使用一个32维双向LSTM来编码一个节点的未来轨迹的ground truth，产生<br><img src="https://i.niupic.com/images/2020/08/02/8u0o.png" alt=""><h4 id="生成动力学可行轨迹"><a href="#生成动力学可行轨迹" class="headerlink" title="生成动力学可行轨迹"></a>生成动力学可行轨迹</h4>在获得一个隐变量z后，将它和ex输入decoder，通过一个128维的GRU，每个GRU细胞的输出作为一个二维高斯分布u(t)的参数从而进行控制（比如加速度和转向率），然后将其与agent系统动力学结合起来获得空间位置。在线性动力学前提下（行人），系统动力学是线性高斯的。<br><img src="https://i.niupic.com/images/2020/08/02/8u0B.png" alt=""><br>在非线性动力学下(独轮车模型)，我们仍然可以使用上述的非线性方案。<br>推导见附录，本文的方法保证了轨迹样本在整合动力学和预测控制之后可以保持动态可行。<h4 id="输出配置"><a href="#输出配置" class="headerlink" title="输出配置"></a>输出配置</h4>根据需求，输出配置有以下四种：<br><img src="https://i.niupic.com/images/2020/08/02/8u0T.png" alt=""><br><img src="https://i.niupic.com/images/2020/08/02/8u0n.png" alt=""><h4 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h4>目标函数<br><img src="https://i.niupic.com/images/2020/08/02/8u0W.png" alt=""><br>InfoVAE的目标函数，然后在条件公式条件下修改以适用于离散隐空间。<h3 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h3>ADE/FDE<br>KDE NLL（Kernel Density Estimate-based Negative Log Likelihood）基于核密度估计的负对数似然估计：ground truth的轨迹与轨迹采样估计出的核密度创造出的分布的平均负对数似然估计。<br>Best-of-N：从N个随机采样轨迹中获得的最小ADE和FDE。<br>特别地，评估阶段为了说明ego-vehicle未来运动计划的影响，做了ablation study，说明了ego-vehicle的未来运动计划是提升表现的重要因素。</li></ol><!-- rebuild by neat -->]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> paper </tag>
            
            <tag> predict trajectory </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CF-LSTM</title>
      <link href="/CF-LSTM.html"/>
      <url>/CF-LSTM.html</url>
      
        <content type="html"><![CDATA[<!-- build time:Fri Jan 01 2021 21:45:28 GMT+0800 (GMT+08:00) --><blockquote class="blockquote-center"><p>CF-LSTM: Cascaded Feature-Based Long Short-Term Networks for Predicting Pedestrian Trajectory</p></blockquote><a id="more"></a><p><img src="https://i.niupic.com/images/2020/08/14/8wmt.png" alt=""><br><img src="https://i.niupic.com/images/2020/08/14/8wmu.png" alt=""><br><img src="https://i.niupic.com/images/2020/08/14/8wmv.png" alt=""><br><img src="https://i.niupic.com/images/2020/08/14/8wmw.png" alt=""></p><!-- rebuild by neat -->]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> paper </tag>
            
            <tag> predict trajectory </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>现代计算机图形学入门07</title>
      <link href="/graphics3.html"/>
      <url>/graphics3.html</url>
      
        <content type="html"><![CDATA[<!-- build time:Fri Jan 01 2021 21:45:28 GMT+0800 (GMT+08:00) --><blockquote class="blockquote-center"><p>GAMES101-现代计算机图形学入门 Lecture 07</p></blockquote><a id="more"></a><h1 id="07-Shading-1-Visibility-Shading-intro-Diffuse-reflection"><a href="#07-Shading-1-Visibility-Shading-intro-Diffuse-reflection" class="headerlink" title="07-Shading 1(Visibility/Shading intro/Diffuse reflection)"></a>07-Shading 1(Visibility/Shading intro/Diffuse reflection)</h1><h2 id="Visibility-occlusion"><a href="#Visibility-occlusion" class="headerlink" title="Visibility/occlusion"></a>Visibility/occlusion</h2><p>Z - buffering 深度缓冲/深度缓存: 我们怎么确定各个光栅化三角形的前后关系?</p><h3 id="Painter’s-Algorithm"><a href="#Painter’s-Algorithm" class="headerlink" title="Painter’s Algorithm:"></a>Painter’s Algorithm:</h3><p>先放什么后放什么:先放最远的,逐渐用近的物体覆盖上去<br>顺序非常讲究了! 我们定义深度(离观测点的距离不容易)<br>将n个三角形进行排序时间复杂度o(nlogn)<br>当两两三角形覆盖的时候(环)我们便没法定义深度关系,自然无法使用画家算法解决</p><h3 id="Z-Buffer"><a href="#Z-Buffer" class="headerlink" title="Z-Buffer"></a>Z-Buffer</h3><p>这是我们现在广泛使用的算法<br>我们对每个三角形不好计算远近关系,但我们对于每个像素可以进行深度计算<br>在生成图像(frame buffer)的同时,同时生成一个深度图(depth buffer)存储像素的深度信息<br><strong>为了简化我们假设z永远是正值(区别之前的相机视图看向-z方向)即远大近小</strong><br>Z-Buffer Algorithm:</p><pre><code>初始化depth buffer to infinite;During rasterization:    for(each triangle T)        for(each sample (x,y,z)in T)            if(z &lt; zbuffer[x,y])            //目前最近的像素                framebuffer[x,y] = rgb;     //更新颜色                zbuffer[x,y] = z;           //更新深度            else;</code></pre><p><img src="https://pic.downk.cc/item/5eccc81fc2a9a83be5ebaf43.png" alt=""></p><p>complexity:我们假设每个三角形都覆盖常数大小的像素,对于n个三角形o(n)→因为我们这里不是进行排序,而是只记录最小值</p><p>那我们绘制三角形的顺序是否有关?无关(假设没有同样深度的像素点)浮点型和浮点型判断相等非常非常困难,所以我们基本上可以认为浮点数不相等.(如何处理相等本课不涉及)</p><p><strong>Most important visibility algorithm:implemented in hardware for all GPSu</strong></p><p>Addtion:在MSAA,我们便不是对每个像素做而是对每个采样点做depth buffer</p><h2 id="Shading-着色"><a href="#Shading-着色" class="headerlink" title="Shading-着色"></a>Shading-着色</h2><p><img src="https://i.loli.net/2020/05/26/2wsVbgYHZkMGmI8.png" alt="微信截图_20200526160806.png"><br>In this course, we define shading as the process of applying a material to an object.(明暗/颜色)</p><h3 id="Illumination-amp-Shading"><a href="#Illumination-amp-Shading" class="headerlink" title="Illumination &amp; Shading"></a>Illumination &amp; Shading</h3><p>最简单的着色模型Blinn-Phong反射模型:<br><img src="https://i.niupic.com/images/2020/05/26/856m.png" alt=""><br>Specular highlights-镜面高光<br>Diffuse reflection-漫反射<br>Ambient lighting-环境光源(间接光照)</p><h3 id="预定义一些东西"><a href="#预定义一些东西" class="headerlink" title="预定义一些东西"></a>预定义一些东西</h3><p>我们可以认为局部范围内shading是作用在平面上,同样我们可以定义法线<em>n</em>方向.另外可以规定观测方向<em>v</em>,光源的光照方向<em>l</em>.计算光线时是作用在一个特定的shading point上<br><img src="https://i.niupic.com/images/2020/05/26/85dm.png" alt=""><br><strong>Shading! = shadow</strong> 我们只考虑光照观测,不考虑其他物体造成的阴影</p><blockquote><p><strong><em>shading is local</em></strong></p></blockquote><h3 id="漫反射Diffuse-Reflection"><a href="#漫反射Diffuse-Reflection" class="headerlink" title="漫反射Diffuse Reflection"></a>漫反射Diffuse Reflection</h3><p>光线将会均匀的反射到不同方向去 But is it easy?<br>我们能够接受多少光线?我们考虑到光是能量,实际观测到明亮程度就是光通量的大小问题.</p><blockquote><p>考虑shading point周围能接受多少能量<br>Lamber’s cosine law<br><img src="https://i.niupic.com/images/2020/05/26/85eE.png" alt=""></p></blockquote><h3 id="光线衰减"><a href="#光线衰减" class="headerlink" title="光线衰减"></a>光线衰减</h3><p>考虑能量守恒,光的强度和距离的平方成反比,由此我们就可以得到有多少光从点光源传播到shading point,我们又结合lamber’s cosine law可以得到可以吸收多少能量.</p><h3 id="Lambertian-Diffuse-Shading"><a href="#Lambertian-Diffuse-Shading" class="headerlink" title="Lambertian (Diffuse) Shading"></a>Lambertian (Diffuse) Shading</h3><p><img src="https://i.niupic.com/images/2020/05/26/85hC.png" alt=""><br>对于shading point为什么会有颜色?吸收一部分能量,散射出去不要的能量,kd则代表了点本身吸收能量的比值(0白1黑),当kd定义成三通道,我们就可以表述漫反射的颜色啦<br>漫反射是均匀反射到不同方向去,所以和观测方向独立无关<br><img src="https://i.niupic.com/images/2020/05/27/862t.png" alt=""></p><h1 id="08-Shading-2-Shading-Pipeline-and-Texture-Mapping"><a href="#08-Shading-2-Shading-Pipeline-and-Texture-Mapping" class="headerlink" title="08-Shading 2(Shading,Pipeline and Texture Mapping)"></a>08-Shading 2(Shading,Pipeline and Texture Mapping)</h1><p>我们的Blinn-Phong反射模型中上节课已经讲到了在一个shading point上的漫反射了.</p><h2 id="Shading-Cont"><a href="#Shading-Cont" class="headerlink" title="Shading Cont."></a>Shading Cont.</h2><h3 id="Specular-Term"><a href="#Specular-Term" class="headerlink" title="Specular Term"></a>Specular Term</h3><p><strong>Intensity depends on view direction</strong><br>什么时候可以看到高光呢?<br>我们的观察方向和镜面反射方向足够接近时.<br><img src="https://i.niupic.com/images/2020/05/27/861R.png" alt=""><br>在Blinn-Phong模型中,我们利用了一个很妙的想法</p><blockquote><p>视角和镜面反射方向接近时,半程向量(half vector)和法线方向接近,所以我们可以做如下判断<br><img src="https://i.niupic.com/images/2020/05/27/861U.png" alt=""><br>我们只需要看半程向量和法线是否接近,用点乘(接近1近,0远)<br>我们简化了,没有考虑光的吸收(blinn-phong模型)<br>参数Ks一般是白色(高光)<br>在max后增加了一个指数p,因为当我们用cosα作为高光判断时容忍度太高了,当相差度数挺远也会产生高光,因此我们加上指数项来限制高光范围.一般来说我们p要取到100以上<br><img src="https://i.niupic.com/images/2020/05/27/862n.png" alt=""></p></blockquote><h3 id="Ambient-Team"><a href="#Ambient-Team" class="headerlink" title="Ambient Team"></a>Ambient Team</h3><p>做一个大胆假设,任何一个点接受环境的光都是相同的,同时又有自己的颜色<br><img src="https://i.niupic.com/images/2020/05/27/862I.png" alt=""><br>和光照方向无关,和观测方向也没有关系,所以其实是一个常数→保证没有一个地方完全是黑的<br>当然这是一个巨大胆的假设,真实情况我们在后来的全局光照会进一步说明.</p><h3 id="Blinn-Phong-Reflection-Model"><a href="#Blinn-Phong-Reflection-Model" class="headerlink" title="Blinn-Phong Reflection Model"></a>Blinn-Phong Reflection Model</h3><p><img src="https://i.niupic.com/images/2020/05/27/8631.png" alt=""><br>我们对场景内所有的点做着色即可.<br>我们可以看出来blinn-phong模型其实是高度简化的,比如物体的凹凸程度</p><p>以上步骤中与观察点和物体间的距离无关,后面会解释.(radiance)</p><h3 id="Shading-Frequencies"><a href="#Shading-Frequencies" class="headerlink" title="Shading Frequencies"></a>Shading Frequencies</h3><p>着色频率(面/顶点/每一个像素)</p><h4 id="Flat-shading-triangle"><a href="#Flat-shading-triangle" class="headerlink" title="Flat shading(triangle)"></a>Flat shading(triangle)</h4><p>求出三角形的法线(两边叉积),然后与视角方向/光线计算,可以看出效果不太好,不太能处理平滑部分</p><h4 id="Gouraud-shading-vertex"><a href="#Gouraud-shading-vertex" class="headerlink" title="Gouraud shading(vertex)"></a>Gouraud shading(vertex)</h4><p>先假设顶点的法线能求,每个顶点进行着色,然后三个顶点组成的三角形内部用插值来做.</p><h4 id="Phong-shading-pixel"><a href="#Phong-shading-pixel" class="headerlink" title="Phong shading(pixel)"></a>Phong shading(pixel)</h4><p>逐像素进行shading,然后三角形间做插值</p><h4 id="着色频率和面的频率也有关系"><a href="#着色频率和面的频率也有关系" class="headerlink" title="着色频率和面的频率也有关系"></a>着色频率和面的频率也有关系</h4><p>我们模型足够复杂的时候,逐面/顶点效果不一定比逐像素差;当三角形个数超过像素数时,逐像素的计算量说不定还会更小<br><img src="https://i.niupic.com/images/2020/05/27/864g.png" alt=""></p><h4 id="我们怎么知道逐顶点-像素的法线方向"><a href="#我们怎么知道逐顶点-像素的法线方向" class="headerlink" title="我们怎么知道逐顶点/像素的法线方向?"></a>我们怎么知道逐顶点/像素的法线方向?</h4><blockquote><p>逐顶点:<br>最好的方式当然是我们已经知道了其本身想表达的几何体的形状再做法线;当然没这么好的事.<br>做一个简化,我们推测一个顶点的法线可以通过其周围的三角形的法线进行加权平均(简化的话可以用简单平均)<br><img src="https://i.niupic.com/images/2020/05/27/8658.png" alt=""></p></blockquote><blockquote><p>逐像素:<br>求出顶点的法线方向,然后用重心坐标插值Barycentric interpolation)来求得,最后标准化<br><img src="https://i.niupic.com/images/2020/05/27/865v.png" alt=""></p></blockquote><h2 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h2><p>所有的东西结合起来称为管线,从最初到最后我们经历了什么过程?Real-time Rendering pipeline表示一系列操作<br>下图就是从三维场景到渲染出二维图像的操作,这个操作在硬件里已经写好了↓<br><img src="https://i.niupic.com/images/2020/05/27/866I.png" alt=""><br>空间的点→屏幕空间上的点→屏幕空间三角形→像素(不同部分)→着色好的像素→输出的图片</p><ul><li>MVP transforms–Vertex Processing</li><li>Smapling triangle coverage–Rasterization</li><li>Z-Buffer Visiblity Tests–Fragment Processing</li><li>Shading–Vertex Processing/Fragment Processing(这里看着色频率)</li><li>Texture mapping–Vertex Processing/Fragment Processing</li></ul><h3 id="Shader-Programs"><a href="#Shader-Programs" class="headerlink" title="Shader Programs"></a>Shader Programs</h3><p>描述单一顶点/像素执行的操作,操作会对所有顶点/像素执行操作.<br>对于像素着色器,我们要告诉这个像素最后的颜色是什么.</p><pre><code>//Example:GLSL fragment shader program(OpenGL)uniform sampler2D myTexture;//纹理uniform vec3 lightDir;//光照固定//全局变量varying vec2 uv;//插值varying vec3 norm;//插值出任何一个法线void diffuseShader(){    vec3 kd; //漫反射系数    kd = texture2d(myTexture,uv);//material color from texture    kd *= clamp(dot(-lightDir,norm),0.0,1.0); //光负方向输入,简化版本未使用I/r²    gl_FragColor = vec4(kd,1.0);//输出像素}//定义任一顶点/像素该如何操作</code></pre><p><a href="http://shadertoy.com/view/ld3Gz2" target="_blank" rel="noopener">Snail Shader Program</a><br>忽略OpenGL只去写Shader就可以的OL项目.</p><h2 id="Texture-Mapping"><a href="#Texture-Mapping" class="headerlink" title="Texture Mapping"></a>Texture Mapping</h2><p>我们希望得到一个三角形,三角形内部是什么亚子的?<br>对于一个物体,着色模型是一样的,不过不同地方颜色不同→物体不同位置漫反射系数不同.</p><h3 id="Surfaces-are-2D"><a href="#Surfaces-are-2D" class="headerlink" title="Surfaces are 2D"></a>Surfaces are 2D</h3><p>3D物体的表面是2D的,对于3D表面上任意一个点可以找到2D图像中对应的一个点(texture)<br>我们要解决的问题就是怎么把3D空间中的三角形映射到2D空间上呢?<br>one.美工加班 two.自动化parameterazition(参数化)<br>总之我们不管哈哈哈哈哈哈哈</p><h3 id="Vsiualization-of-Texture-Coordinates"><a href="#Vsiualization-of-Texture-Coordinates" class="headerlink" title="Vsiualization of Texture Coordinates"></a>Vsiualization of Texture Coordinates</h3><p>纹理上也应该有对应的坐标系(uv)<br>对于纹理来说,u<del>(0,1)v</del>(0,1)<br>纹理可以重复使用多次!(tiled textures)Wang Tiling</p><h1 id="09-Shading-3-Texture-Mapping-Cont"><a href="#09-Shading-3-Texture-Mapping-Cont" class="headerlink" title="09-Shading 3(Texture Mapping Cont.)"></a>09-Shading 3(Texture Mapping Cont.)</h1><h2 id="Shading-Cont-1"><a href="#Shading-Cont-1" class="headerlink" title="Shading Cont."></a>Shading Cont.</h2><h3 id="Barycentric-coordinates"><a href="#Barycentric-coordinates" class="headerlink" title="Barycentric coordinates"></a>Barycentric coordinates</h3><p>在三角形内部进行插值→Why?<br>我们得到了顶点的属性,我们希望三角形内平滑的过渡<br>我们希望插入什么内容?<br>Texture coordinates材质坐标, colors颜色 , 法线向量<br>怎么做插值?<br>重心坐标(用(α,β,γ)来表示一个点)<br><img src="https://i.niupic.com/images/2020/05/27/86jH.png" alt=""><br>用三角形三个顶点的坐标来表示三角形内部的点(顶点坐标怎么表示就无所谓了)<br>在三角形内部是α β γ均非负<br>我们计算重心坐标可以借助三角形面积比<br><img src="https://i.niupic.com/images/2020/05/27/86jZ.png" alt=""><br>三角形自身的重心的重心坐标(α,β,γ)=(1/3,1/3,1/3)<br>当然在直角坐标系中我们有直接计算的公式<br><img src="https://i.niupic.com/images/2020/05/27/86k6.png" alt=""></p><p>得到重心坐标后,我们便可以通过重心坐标进行插值:<br>对于已知三个顶点的属性,我们线性组合利用重心坐标就可以得到内部的属性值<br><img src="https://i.niupic.com/images/2020/05/27/86ke.png" alt=""><br>我们要注意到,就是在投影变换下不能保持重心坐标不变.<br>如果想插值三维中的属性,那么利用三维中的坐标进行重心坐标线性变换<br>例如之前提到的深度插值,我们就应该直接在三维空间中做插值再对应到二维结果中.</p><h2 id="Texture-queries"><a href="#Texture-queries" class="headerlink" title="Texture queries"></a>Texture queries</h2><h3 id="Texture-Mapping-Diffuse-Color"><a href="#Texture-Mapping-Diffuse-Color" class="headerlink" title="Texture Mapping:Diffuse Color"></a>Texture Mapping:Diffuse Color</h3><p>Simple Way:</p><pre><code>for each rasterized screen sample (x,y):    (u,v)=evaluate texture coordinate at (x,y);//使用重心坐标    texcolor=texture.sample(u,v);    set sample&apos;s color to texcolor;//漫反射系数  </code></pre><h3 id="Texture-Magnification-TOO-SMALL"><a href="#Texture-Magnification-TOO-SMALL" class="headerlink" title="Texture Magnification-TOO SMALL"></a>Texture Magnification-TOO SMALL</h3><p>如果我们的纹理太小了怎么办?高清的模型/低清的材质<br>我们去找到材质上的pixel–我们称为texel(纹理元素),那么当给出的坐标不是整数的时候我们采取一下几种方法:</p><ol><li>Nearest:直接找最近的–形成一块一块的</li><li>Bilinear interpolation: 双线性插值<br><img src="https://i.niupic.com/images/2020/05/27/86le.png" alt=""><br>水平两次差值+竖直一次插值</li><li>Bicubic:双三次插值→取周围的16个,四个一组做差值,再做插值.<h3 id="Texture-Magnification-TOO-LARGE"><a href="#Texture-Magnification-TOO-LARGE" class="headerlink" title="Texture Magnification-TOO LARGE"></a>Texture Magnification-TOO LARGE</h3><img src="https://i.niupic.com/images/2020/05/27/86pS.png" alt=""><br>一个像素覆盖纹理贴图的区域是不同的,近覆盖小远覆盖多<br>Antialiasing-一个像素内包含多个纹理值,频率很高,但只用一个像素进行采样,必然会导致走样现象<br>自然而然我们想到超采样方法,但是太昂贵了</li></ol><p><em>我们进行另外一条方式,如果我们不采样呢?我们想得到一个区域的值的平均</em><br>too small中Point Query(点查询)VStoo large中Range Query(面查询,且这里我们是avg.)</p><p><strong><em>Mipmao</em></strong>允许我们进行范围查询(Fast(快速),Approx.(近似),Square(近似正方形的))<br>Mip meaning a multitude in a small space<br><img src="https://i.niupic.com/images/2020/05/27/86qn.png" alt=""><br>额外存储1/3原图的存储量(1/4+1/16+1/64+…)<br><img src="https://i.niupic.com/images/2020/05/27/86qt.png" alt=""><br>这样我们可以得到原图压缩1 2 3 …次后的图像<br><img src="https://i.niupic.com/images/2020/05/27/86qG.png" alt=""><br><img src="https://i.niupic.com/images/2020/05/27/86qN.png" alt=""><br>我们通过把屏幕上的像素点映射到纹理空间后,通过计算就可以得到应该在D=?级进行面查询了,D重要!设想当正方形边长L=4,那么对应mipmap中第二层对应的纹理图<br>近用底层,远用顶层,但是现在因为层数是离散的,所以会显示不连续–需要插值!</p><p>Trilinear Interpolation<br><img src="https://i.niupic.com/images/2020/05/27/86r6.png" alt=""><br>两个层分别做双线性插值(),在层与层之间(D是离散的)再进行插值<br>→三线性插值<br>但是Mipmap会产生远处过于模糊的现象<br>仅仅用一个正方形进行框定.<br><img src="https://i.niupic.com/images/2020/05/27/86so.png" alt=""></p><blockquote><p>为了解决这个问题→各项异性过滤(Anisotropic Filtering)→比起mipmap多了一些水平、竖直方向的图像(ripmap),从而并不是单单用一个正方形来进行框定<br>2x就是竖直压缩一次,4x就是压缩两次,最后收敛到3倍,应用各项异性过滤显存够用的时候开到最高就行了:)<br>解决了矩形部分的查询<br>总共的开销变成了原来的三倍</p></blockquote><p>更加不规则的??EWA 比如那个斜着的?还有更多过滤办法233<br>!()[<a href="https://i.niupic.com/images/2020/05/27/86ss.png]" target="_blank" rel="noopener">https://i.niupic.com/images/2020/05/27/86ss.png]</a><br>比如EWA过滤,任意不规律的形状,可以拆成不同的圆形,多次查询</p><!-- rebuild by neat -->]]></content>
      
      
      <categories>
          
          <category> 课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graphics </tag>
            
            <tag> lessons </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>罗德里德斯旋转公式</title>
      <link href="/rodrigues.html"/>
      <url>/rodrigues.html</url>
      
        <content type="html"><![CDATA[<!-- build time:Fri Jan 01 2021 21:45:28 GMT+0800 (GMT+08:00) --><blockquote class="blockquote-center"><p>本文是计算机图形学中罗德里德斯旋转公式的证明</p></blockquote><a id="more"></a><p><img src="https://pic.downk.cc/item/5ecbf8f6c2a9a83be5f10998.jpg" alt=""><br><img src="https://pic.downk.cc/item/5ecbf903c2a9a83be5f11a7a.jpg" alt=""></p><!-- rebuild by neat -->]]></content>
      
      
      <categories>
          
          <category> 证明 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graphics </tag>
            
            <tag> proof </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>现代计算机图形学入门04-06</title>
      <link href="/graphics2.html"/>
      <url>/graphics2.html</url>
      
        <content type="html"><![CDATA[<!-- build time:Fri Jan 01 2021 21:45:28 GMT+0800 (GMT+08:00) --><blockquote class="blockquote-center"><p>GAMES101-现代计算机图形学入门 Lecture 04-06</p></blockquote><a id="more"></a><h1 id="04-Transformation-Cont"><a href="#04-Transformation-Cont" class="headerlink" title="04-Transformation Cont"></a>04-Transformation Cont</h1><h2 id="3D-transformations"><a href="#3D-transformations" class="headerlink" title="3D transformations"></a>3D transformations</h2><ul><li>Linear map和translation基本都没啥大变化</li><li>需要注意的是旋转<br><img src="https://pic.downk.cc/item/5eca952bc2a9a83be5491ac7.png" alt=""><br>注意到对x/z旋转正常,对y旋转的符号问题 - z叉乘x得到y 观测是从z轴→x轴,但是矩阵对应x轴→z轴 故需要取转置/逆矩阵</li><li>Compose any 3D rotation from Rx Ry Rz <strong>euler angle</strong><br><img src="https://pic.downk.cc/item/5eca9690c2a9a83be54b1e81.png" alt=""></li><li>Rodrigues’ Rotation Formula 罗德里德斯旋转公式<br>定义了旋转角度 α 沿 <em>n</em> 轴方向旋转(我们默认旋转时起点在原点上),(n是单位向量)<br><img src="https://pic.downk.cc/item/5ecb2748c2a9a83be5d48740.png" alt=""> #证明另见</li><li>补充四元数:旋转角度的差值问题</li></ul><h2 id="Viewing-transformation"><a href="#Viewing-transformation" class="headerlink" title="Viewing transformation"></a>Viewing transformation</h2><h3 id="View-Camera-transformation"><a href="#View-Camera-transformation" class="headerlink" title="View/Camera transformation"></a>View/Camera transformation</h3><p>视图变换</p><h4 id="what-is-view-transformation"><a href="#what-is-view-transformation" class="headerlink" title="what is view transformation?"></a>what is view transformation?</h4><p>** how to take a photo?**</p><ul><li>先找一个好地方,把人安排好 model transformation</li><li>找到一个好角度,放置相机 view transformation</li><li>拍照~ projection transformation</li><li>简称MVP变换<h4 id="how-to-perform-view-transformation"><a href="#how-to-perform-view-transformation" class="headerlink" title="how to perform view transformation"></a>how to perform view transformation</h4>先定义相机</li><li>位置</li><li>看向的方向</li><li>相机的上方方向(防止旋转)<br>当相机和所有的物体一起移动,那么照片会一直一样</li></ul><p><strong>我们把相机永远放在原点,并且看向-z方向,上方向是Y(约定俗成)</strong><br><strong>实际我们是将所有物体相对相机移动</strong></p><h4 id="Transform-matrix"><a href="#Transform-matrix" class="headerlink" title="Transform matrix"></a>Transform matrix</h4><p>位置移到原点<br>看向方向旋转到-z<br>向上方向旋转到y<br>同时看向方向和向上方向的叉乘到x<br>数学表示<br><img src="https://pic.downk.cc/item/5ecb2c2bc2a9a83be5d8163d.png" alt=""></p><ul><li>先用坐标轴到目标方向进行表示比较容易理解,先求简单问题再求逆</li><li>相机如此变换,其他物体也都需要这样变换</li></ul><p><strong>所以我们实际是对物体和相机一同变换,变换形式是一样的,所以又叫ModelView Transformation</strong><br>接下来我们接觉 投影变化</p><h3 id="Projection-transformation"><a href="#Projection-transformation" class="headerlink" title="Projection transformation"></a>Projection transformation</h3><p>3D to 2D</p><blockquote><p>正交投影→工程制图 本质→不会带来近大远小现象<br>透视投影→人眼 平行线不再平行 会相交 本质→会近大远小</p></blockquote><p><img src="https://pic.downk.cc/item/5ecb309ec2a9a83be5dc7b0d.png" alt=""><br>把透视投影中相机拉到无限远→正交投影</p><h4 id="Orthographic-projection"><a href="#Orthographic-projection" class="headerlink" title="Orthographic projection"></a>Orthographic projection</h4><p><strong>一种简单的理解方式</strong>:</p><ul><li>相机扔到原点,看向-z,向上y</li><li>直接丢到 z 坐标</li><li>平移并缩放至 [-1,1]² 约定俗成</li></ul><p><strong>General的方式</strong></p><ul><li>对于任意一个长方体(cuboid)映射到一个[-1,1]³正则正方体(canonical)上</li><li>上述变化通过平移缩放实现</li><li>We want to map a cuboid [l, r] x [b, t] x [f, n] to the “canonical (正则、规范、标准)” cube [-1, 1]³</li><li>注意这里f是远,n是近,远z值小,近z值大(因为是向-z看去)<br><img src="https://pic.downk.cc/item/5ecb339ec2a9a83be5e0faa3.png" alt=""></li><li>会拉伸,后面会再进行处理回去,我们这里做的是正则标准化处理</li></ul><h4 id="Perspective-projection"><a href="#Perspective-projection" class="headerlink" title="Perspective projection"></a>Perspective projection</h4><p>在计算机图形学中应用最广泛<br>近大远小,平行线不再平行,会交于一点<br>(欧式几何是在同一平面内,而我们则是涉及到不同的平面和角度)</p><ul><li>回忆homogeneous coordinates</li><li>(x,y,z,1),(kx,ky,kz,k!=0),(xz,yz,z²,z!=0)都可以代表3D平面内同一个点(x,y,z)</li><li>将锥体的远平面挤成正则立方体,然后做正交投影(已知)<ul><li>近平面上的点永远不变</li><li>z 不变</li><li>远平面的中心点不发生变化</li><li>远平面挤压过后z大小会变成近平面处大小,故我们可以进行相似三角形处理,x’和y’得到的方式一样</li><li><img src="https://pic.downk.cc/item/5ecb3ba9c2a9a83be5ee06bf.png" alt=""></li><li><img src="https://pic.downk.cc/item/5ecb3bbcc2a9a83be5ee1d12.png" alt=""><br>关键点来了,我们的变换目标在齐次坐标系中如下<br><img src="https://pic.downk.cc/item/5ecb3c30c2a9a83be5eed114.png" alt=""><br>即我们的原向量经过变换后变为现在的向量,所以可以我们的压缩矩阵便可解出一部分了<br><img src="https://pic.downk.cc/item/5ecb3d1cc2a9a83be5f013e9.png" alt=""><br>根据我们之前的观察:近平面上的点变换后不变.远平面的z都不变化</li></ul></li></ul><ol><li>近平面上点<br><img src="https://pic.downk.cc/item/5ecb3eaac2a9a83be5f24ef3.png" alt=""></li><li>远平面上的中心点<br><img src="https://pic.downk.cc/item/5ecb3eb8c2a9a83be5f266ee.png" alt=""><br>可以解得<br>A = n + f<br>B = -nf<br>至此我们便得到了挤压矩阵,再乘以正交矩阵便可以得到透视矩阵了<br><img src="https://pic.downk.cc/item/5ecb4a7dc2a9a83be5052258.png" alt=""></li></ol><h1 id="05-Rasterization-1-Triangles"><a href="#05-Rasterization-1-Triangles" class="headerlink" title="05-Rasterization 1(Triangles)"></a>05-Rasterization 1(Triangles)</h1><h2 id="Finishing-up-Viewing"><a href="#Finishing-up-Viewing" class="headerlink" title="Finishing up Viewing"></a>Finishing up Viewing</h2><h3 id="Perspective-Projection"><a href="#Perspective-Projection" class="headerlink" title="Perspective Projection"></a>Perspective Projection</h3><p>在上一个透视投影中,我们已经讲到了要压缩成和近平面一样的长宽,那么近平面长宽是什么呢?<br>如果特殊指出来了,很好,但是如果没有,我们可以用fovY(field-of-view)和aspect ratio来共同定义.<br><img src="https://pic.downk.cc/item/5ecb62d1c2a9a83be52e096f.png" alt=""><br>那么我们就可以从fovY转换到近平面的长宽了<br><img src="https://pic.downk.cc/item/5ecb636cc2a9a83be52ee3bb.png" alt=""><br>由上我们便可以定义一个视锥</p><h3 id="what’s-after-MVP"><a href="#what’s-after-MVP" class="headerlink" title="what’s after MVP"></a>what’s after MVP</h3><p>得到了canonical cube后我们要把它画在屏幕上</p><ul><li>what is a screen<ul><li>一个像素的数组</li><li>数组的大小:分辨率 表示像素多少</li><li>一种典型的光栅显示设备</li><li>rasterize == drawing onto the screen</li><li>pixel:我们目前认为它是一个个不同颜色的小方块/颜色是由RGB混合</li><li>屏幕空间:像素坐标(0,0)到(width-1,height-1);像素(x,y)的中心位于(x+0.5,y+0.5)则屏幕空间为(0,0)到(width,height)</li></ul></li><li>Canonical cube to screen<ul><li>此处与z无关</li><li>(x,y)由[-1,1]²到[0,width]*[0,height]</li><li>Viewport transform matrix 视口变换:<br><img src="https://pic.downk.cc/item/5ecb674bc2a9a83be5346ed9.png" alt=""></li><li>可以看到是长宽做了scaling 然后平移中心(我们定义屏幕左下角为坐标原点所以中心要移)</li></ul></li></ul><h2 id="Rasterization"><a href="#Rasterization" class="headerlink" title="Rasterization"></a>Rasterization</h2><p>Drawing to raster displays</p><h3 id="Triangle-Meshes"><a href="#Triangle-Meshes" class="headerlink" title="Triangle Meshes"></a>Triangle Meshes</h3><ul><li>三角形是最基本的多边形,任何其他的多边形都可以拆成三角形</li><li>三角形内部一定是同一平面的</li><li>三角形内外部定义良好(向量叉积还可以判断内外)</li><li>三角形定义好三点后,可以定义一个渐变(插值)方法</li></ul><p>那么我们怎么用像素值来大体表示三角形呢?<br>Key concept:判断像素中心点与三角形位置关系</p><blockquote><p>A simple approach: Sampling(采样)<br>采样就是把一个函数离散化的过程<br>采样是图形学中核心观念,我们可以用1D(time)2D(area,direction)3D(volume)进行采样</p></blockquote><p>Define Binary Function:inside(tri,x,y)<br><img src="https://pic.downk.cc/item/5ecb7435c2a9a83be548f9e8.png" alt=""></p><pre><code>for(int x = 0 ; x &lt; xmax; ++x )  for(int y = 0; y &lt; ymax; ++y)    image[x][y] = inside(tri,x + 0.5,y + 0.5);</code></pre><p>那么怎么判断是否在内部呢?<br><strong>使用三次向量叉乘</strong></p><p>Edge Cases:当采样点正好在两个三角形边界位置怎么处理?(自己定义一个标准)</p><p>加速条件:<br>考虑一个三角形光栅化时,按上述代码,我们要扫描整个屏幕,实际没必要.我们可以使用包围盒(Bounding Box)<br><img src="https://pic.downk.cc/item/5ecb768fc2a9a83be54c915e.png" alt=""><br>上图便是一个轴向的包围盒,也可叫做axies-aligned bounding box(AABB)</p><p>Incremental Triangle Traversal<br><img src="https://pic.downk.cc/item/5ecb7762c2a9a83be54dca52.png" alt=""><br>对于瘦长又旋转的三角形,我们可以用上图方法进行处理(但可能不好做?具体问题具体分析叭!)</p><p><strong><em>Summary 我们就是用过采样Inside函数,得到光栅化.就是每个可能像素检测是否在三角形内</em></strong></p><h3 id="Rasterization-on-Real-Displays"><a href="#Rasterization-on-Real-Displays" class="headerlink" title="Rasterization on Real Displays"></a>Rasterization on Real Displays</h3><p>实际上pixel并不是一个个小方块;事实上人眼对于绿色的感知更敏感,所以可能绿色会更多一些<br>打印: 省墨水/颜色越多越黑/减色系统 屏幕RGB越高越白</p><p>当我们已经把采样信号发往显示器了,然后捏?<br>锯齿问题非常严重!(Jaggies)采样率不够高,从而产生走样现象(Aliasing)<br>所以我们的一个重要目标就是抗锯齿.</p><h1 id="06-Rasterization-2-Antialiasing-and-Z-Buffering"><a href="#06-Rasterization-2-Antialiasing-and-Z-Buffering" class="headerlink" title="06-Rasterization 2(Antialiasing and Z-Buffering)"></a>06-Rasterization 2(Antialiasing and Z-Buffering)</h1><h2 id="Antialiasing"><a href="#Antialiasing" class="headerlink" title="Antialiasing"></a>Antialiasing</h2><p>锯齿/走样→抗锯齿/反走样</p><h3 id="sampling-artifacts"><a href="#sampling-artifacts" class="headerlink" title="sampling artifacts"></a>sampling artifacts</h3><p>采样是图形学中广泛的方法<br>但会产生Artifacts(Erros/Mistakes/Inaccuracies)</p><ol><li>Jaggies 锯齿</li><li>Moire 摩尔纹 Skip odd rows and columns隔行采样</li><li>Wagon wheel effect 轮子倒转 在时间采样上出现问题</li></ol><p><strong>本质:信号变换速度过快(high frequency)而采样速度过慢</strong></p><h3 id="Antialiasing-Idea-Blurring-pre-filtering-before-sampling"><a href="#Antialiasing-Idea-Blurring-pre-filtering-before-sampling" class="headerlink" title="Antialiasing Idea:Blurring(pre-filtering) before sampling"></a>Antialiasing Idea:Blurring(pre-filtering) before sampling</h3><p>在采样前进行滤波(模糊操作),再进行采样,便可以达成抗锯齿的效果<br>(模糊之后,采样该什么颜色就用什么颜色)<br>采样之后再进行模糊→Blurred Aliasing达不到效果</p><h3 id="Frequency-Domain"><a href="#Frequency-Domain" class="headerlink" title="Frequency Domain"></a>Frequency Domain</h3><p><strong>Frequency Domain 频域</strong><br>频率 cos(2πf x) f = 1/T<br>傅里叶级数展开:任何一个周期函数都可以写成一系列正余弦线性组合和一个常数项的和,(eg用不同正余弦去逼近矩形波)<br>傅里叶变换:将信号变换为频率/逆傅里叶变换:频率变换为信号<br><img src="https://pic.downk.cc/item/5ecb8b85c2a9a83be56b7b54.png" alt=""><br>实质就是把函数变成不同频率段并把频率段显示出来<br>当频率变高之后,我们就很不容易用采样将原来的函数恢复出来<br><img src="https://pic.downk.cc/item/5ecb8c5dc2a9a83be56ca71e.png" alt=""><br><img src="https://pic.downk.cc/item/5ecb8c6bc2a9a83be56cbecf.png" alt=""><br>两种频率截然不同,但是采样频率给定时,获得同样的信息,也就是走样.</p><h3 id="Filtering"><a href="#Filtering" class="headerlink" title="Filtering"></a>Filtering</h3><p>滤波:去掉一些特定的频率内容<br>对图像进行傅里叶变换→时域变换到频域<br><img src="https://pic.downk.cc/item/5ecb8edcc2a9a83be570374b.png" alt=""><br>中间是低频信息,四周是高频信息,而亮度则代表了包含信息的多少<br>对于真实图片,大部分的信息都集中在低频部分</p><blockquote><p>水平和竖直的线: 分析信号时会默认为周期性信号,那么对于不周期信号来说,比如这张图,我们认为到了图的右边界后又从图的左边界进入;上下边界同理;即我们叠了好多好多张图.正常情况下图的左右边界信号会产生剧烈变化,也就会产生高频.</p></blockquote><p>傅里叶变换可以让我们看到信号的频率分布!<br>我们使用<strong>高通滤波</strong>,可以看到只保留了图像的边界(灰度发生剧烈变化的地方)<br><img src="https://pic.downk.cc/item/5ecb90c5c2a9a83be572846f.png" alt=""><br>我们使用<strong>低通滤波</strong>,可以看到图像变得十分模糊,细节全部去除<br><img src="https://pic.downk.cc/item/5ecb9143c2a9a83be573317a.png" alt=""><br>下面我们再进行把高通和低通都滤掉<br><img src="https://pic.downk.cc/item/5ecb9244c2a9a83be5743c40.png" alt=""><br><img src="https://pic.downk.cc/item/5ecb924bc2a9a83be57443cb.png" alt=""><br>更多知识去学习数字图像处理;但是现在更多是用机器学习来做处理</p><h3 id="Filtering-Averaging-Convolution"><a href="#Filtering-Averaging-Convolution" class="headerlink" title="Filtering = Averaging = Convolution"></a>Filtering = Averaging = Convolution</h3><p>卷积窗口blahblahblah 窗口和信号重叠部分做点乘作为结果,形式上就是加权取平均<br><strong>Convolution Theorem</strong><br>Convolution in the spatial domain is equal to multiplication in the frequency domain,and vice versa.<br>时域上想对两个信号进行卷积,就和两个信号频域上的乘积相等(另一半时域相乘就是频域卷积)<br>我们可以直接:</p><ol><li>直接在时域进行卷积</li><li>频域变换<ul><li>将图和卷积滤波器傅里叶变换到频域</li><li>频域上频谱相乘</li><li>逆傅里叶变换变换回时域<br><img src="https://pic.downk.cc/item/5ecb9799c2a9a83be57b06d1.png" alt=""><br>上面使用的是Box Filter 盒子变大→频率上变小,提取更低频的信号</li></ul></li></ol><h3 id="Sampling-Repeating-grequency-contents"><a href="#Sampling-Repeating-grequency-contents" class="headerlink" title="Sampling = Repeating grequency contents"></a>Sampling = Repeating grequency contents</h3><p>冲激函数,只在固定时间有值,其余位置无值<br><img src="https://pic.downk.cc/item/5ecb9991c2a9a83be57d6cf4.png" alt=""><br>↑时域上的乘积,是频域上的卷积</p><h3 id="Aliasing-Mixed-Frequency-Contents"><a href="#Aliasing-Mixed-Frequency-Contents" class="headerlink" title="Aliasing = Mixed Frequency Contents"></a>Aliasing = Mixed Frequency Contents</h3><p><img src="https://pic.downk.cc/item/5ecb9a1fc2a9a83be57dfa76.png" alt=""><br>采样不够快,冲激函数在频域内的间隔是时域中的倒数,那么频域的间隔会变小;频谱发生了混叠→Artifacts</p><h3 id="how-to-reduce-aliasing-error"><a href="#how-to-reduce-aliasing-error" class="headerlink" title="how to reduce aliasing error"></a>how to reduce aliasing error</h3><ol><li>提高采样率,那么频谱自然不混叠,但是这就要求更高分辨率的显示设备,受限于物理限制,(<del>分辨率1024K肯定看不出来锯齿了ovo</del></li><li>Antialiasing 先模糊后采样, 先低通滤波截取高频信号, 然后就使频谱不再混叠.Limiting,then repeating.<br><img src="https://pic.downk.cc/item/5ecb9c99c2a9a83be580a0cd.png" alt=""><br>常规的采样中,我们的像素值非A即B;而进行反走样操作后,我们的像素值会取中间值<h3 id="Practical-Pre-Filter"><a href="#Practical-Pre-Filter" class="headerlink" title="Practical Pre-Filter"></a>Practical Pre-Filter</h3>取一个像素宽度的box filter,起到低通(模糊)操作.<br>先卷积再采样.<br>对于任何一个覆盖像素内部,我们都根据三角形覆盖其中的面积做卷积,得到不同大小的像素值.<br>但是面积很难进行计算,所以我们下面将采取一种近似方法进行处理<h3 id="Antialiasing-by-supersampling-MSAA-multi-sampled-antialising"><a href="#Antialiasing-by-supersampling-MSAA-multi-sampled-antialising" class="headerlink" title="Antialiasing by supersampling(MSAA = multi-sampled antialising)"></a>Antialiasing by supersampling(MSAA = multi-sampled antialising)</h3>我们认为上面的一个像素内部又进行划分,划分为4个小的像素,然后分别用这4个小像素进行计算取平均(2x2 MSAA)<br><img src="https://pic.downk.cc/item/5ecb9fb4c2a9a83be5840ea7.png" alt=""><br><img src="https://pic.downk.cc/item/5ecb9fbdc2a9a83be58416c0.png" alt=""><br><img src="https://pic.downk.cc/item/5ecb9fc5c2a9a83be5841da1.png" alt=""><br><img src="https://pic.downk.cc/item/5ecb9fccc2a9a83be5842541.png" alt=""><br><img src="https://pic.downk.cc/item/5ecb9fd6c2a9a83be5842f49.png" alt=""><br><img src="https://pic.downk.cc/item/5ecb9fe0c2a9a83be584370b.png" alt=""><br>完成这一步相当于我们进行了上述模糊的操作(得到一个近似的三角形覆盖率),然后再进行采样就能起到抗锯齿的作用(其实已经隐含在上一步了)</li></ol><h3 id="Antialiasing-Today"><a href="#Antialiasing-Today" class="headerlink" title="Antialiasing Today"></a>Antialiasing Today</h3><ul><li>No free lunch!</li><li>我们做MSAA用更多的点进行测试,增大了很多计算量(2x2=4)</li><li>其实工业界中像素分布不均匀,而且样本会进行复用,样本怎样分布会影响性能,所以实际多重采样并不是线性增大计算量\<blockquote><p>抗锯齿方案里程碑:<br>FXAA(Fast Approximate AA)非增加采样,是先得到有锯齿的图,然后把锯齿消除,消除的方法是用没有锯齿的边界进行替换(注意前面说过不能先Sampling再Filter)<br>TAA(Tem’poral AA)近几年兴起,与时间相关.找上一帧的信息.在静止场景内,我们可以用一个像素内不同位置的点来感知是否在三角形内.在时间范围内,我们复用上一步感知得到的的结果并应用进来</p></blockquote></li><li>Super resolution / super sampling<ul><li>from low resolution to high resolution</li><li>与反走样不是一回事但是本质相同,实际上还是样本不足</li><li>DLSS:Deep Learning Super Sampling 用深度学习猜测局部细节问题</li></ul></li></ul><!-- rebuild by neat -->]]></content>
      
      
      <categories>
          
          <category> 课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graphics </tag>
            
            <tag> lessons </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>现代计算机图形学入门01-03</title>
      <link href="/graphics1.html"/>
      <url>/graphics1.html</url>
      
        <content type="html"><![CDATA[<!-- build time:Fri Jan 01 2021 21:45:28 GMT+0800 (GMT+08:00) --><blockquote class="blockquote-center"><p>GAMES101-现代计算机图形学入门 Lecture 01-03</p></blockquote><a id="more"></a><h1 id="01-Overview-of-Computer-Graphics"><a href="#01-Overview-of-Computer-Graphics" class="headerlink" title="01-Overview of Computer Graphics"></a>01-Overview of Computer Graphics</h1><h2 id="what-is-computer-graphics"><a href="#what-is-computer-graphics" class="headerlink" title="what is computer graphics"></a>what is computer graphics</h2><h2 id="why-study-computer-graphics"><a href="#why-study-computer-graphics" class="headerlink" title="why study computer graphics"></a>why study computer graphics</h2><ul><li>好的画面?画面是否足够亮:渲染技术的全局光照</li><li>Spicial effect:最简单的应用,特殊效果.</li><li>真实/仿真:难!</li><li>Animations:毛发数量多/光线和毛发交互?几何表述/渲染/计算光线</li><li>Design:CAD CG-PHOTO</li><li>Visualization 可视化 近年独立</li><li>Virtual Reality</li><li>Digital Illustration</li><li>Simulation</li><li>Graphical User Interfaces:GUI 今年独立</li><li>Typography 字体设计部分</li></ul><p><strong>fundamental intellectual/technical challenges</strong></p><h2 id="course-topics"><a href="#course-topics" class="headerlink" title="course topics"></a>course topics</h2><ol><li>rasterization 光栅化 OpenGL 实时将三维投影到二维/30fps</li><li>cuves and meshes 曲线/曲面 怎么表示?</li><li>ray tracing 光线追踪</li><li>animation/simulation 动画/模拟</li></ol><p>Course NOT ABOUT<br>using OPENGL/DirectX/Vulcan-API 3D modeling using Maya/unity/unreal engine computer vision/deep learning</p><h2 id="course-logistics"><a href="#course-logistics" class="headerlink" title="course logistics"></a>course logistics</h2><p>assignments <a href="http://www.smartchair.org/GAMES2020Course-YLQ/" target="_blank" rel="noopener">http://www.smartchair.org/GAMES2020Course-YLQ/</a><br>Use An IDE- VS / VS Code</p><h1 id="02-Review-of-Linear-Algebra"><a href="#02-Review-of-Linear-Algebra" class="headerlink" title="02-Review of Linear Algebra"></a>02-Review of Linear Algebra</h1><h2 id="graphics’-dependencies"><a href="#graphics’-dependencies" class="headerlink" title="graphics’ dependencies"></a>graphics’ dependencies</h2><ul><li>basic mathematics- linear algebra, calculus, statistics</li><li>basic physics- optics mechanics</li><li>Misc- signal processing, numerical analysis</li><li>a bit of aesthetics<br>More dependent on linear algebra<h2 id="Vectors"><a href="#Vectors" class="headerlink" title="Vectors"></a>Vectors</h2></li><li>向量/矢量 direciton and length / no absolute starting position</li><li>vector normalization: Magnitude ||<em>a</em>|| unit vector ahat = <em>a</em>/||<em>a</em>||</li><li>图形学中向量缺省设置为列向量<br>$$A=\binom{x}{y}$$</li><li>Dot(scalar) Product-scalar<br>点乘可以快速得到1.两向量间夹角2.一个向量投影到另一向量3.两个向量前后信息</li><li>Cross product<br>叉乘结果永远垂直于a b的平面/右手定则/不满足交换律<br>建立三维空间的空间坐标系(右手坐标系) x X y=z<br>叉乘可以得到</li></ul><p>1.左右信息-右手坐标系里,x叉乘y与z正向一致则x在y右侧<br>2.内外信息<br><img src="https://pic.downk.cc/item/5eca31b6c2a9a83be5dd039a.png" alt=""><br>如图AB叉乘AP BC叉乘BP CA叉乘CP分别都得到左侧信息,那么p就在三角形ABC内部<br>这便是<strong>三角形光栅化基础</strong><br>当叉乘得到0→CornerCase自己规定</p><h2 id="Matrices"><a href="#Matrices" class="headerlink" title="Matrices"></a>Matrices</h2><ul><li>Matrix-Matrix multiplication (M X N)(N x P) = (M x P)<br>无交换律,有结合律</li><li>Matrix-Vector multiplication<br>Treat vector as a column matrix/Key for transforming points</li><li>Transpose of a Matrix<br>transpose(AB)=transpose(B)transpose(A)</li><li>Vector multiplication in Matrix form<br>dot prodect<br><img src="https://pic.downk.cc/item/5eca34b0c2a9a83be5df63dc.png" alt=""><br>cross product<br><img src="https://pic.downk.cc/item/5eca34bdc2a9a83be5df74ca.png" alt=""><br>在旋转推导上,这里非常有用</li></ul><h1 id="03-Transformation"><a href="#03-Transformation" class="headerlink" title="03-Transformation"></a>03-Transformation</h1><h2 id="why-study-transformation"><a href="#why-study-transformation" class="headerlink" title="why study transformation"></a>why study transformation</h2><ul><li>modeling 模型变换<ul><li>translation</li><li>rotation</li><li>scaling</li></ul></li><li>view 视图变换<ul><li>3D to 2D projection<h2 id="2D-transformation"><a href="#2D-transformation" class="headerlink" title="2D transformation"></a>2D transformation</h2><h3 id="Scale"><a href="#Scale" class="headerlink" title="Scale"></a>Scale</h3><blockquote><p>x’ = sx<br>y’ = sy<br><img src="https://pic.downk.cc/item/5eca3fe2c2a9a83be5e9612f.png" alt=""><br>不均匀缩放?<br><img src="https://pic.downk.cc/item/5eca401cc2a9a83be5e991fc.png" alt=""></p></blockquote><h3 id="Reflection-matrix"><a href="#Reflection-matrix" class="headerlink" title="Reflection matrix"></a>Reflection matrix</h3><blockquote><p>horizontal reflection:<br>x’ = -x<br>y’ = y<br><img src="https://pic.downk.cc/item/5eca4067c2a9a83be5e9d7a5.png" alt=""></p></blockquote><h3 id="Shear-matrix"><a href="#Shear-matrix" class="headerlink" title="Shear matrix"></a>Shear matrix</h3><blockquote><p>Hints:<br>Horizontal shift is 0 at y = 0<br>Horizontal shift is a at y = 1<br>Vertical shift is always 0<br>y’ = y<br>x’ = x + a*y<br><img src="https://pic.downk.cc/item/5eca4240c2a9a83be5ebd614.png" alt=""></p></blockquote><h3 id="Rotate"><a href="#Rotate" class="headerlink" title="Rotate"></a>Rotate</h3><blockquote><p><img src="https://pic.downk.cc/item/5eca446cc2a9a83be5ee2272.png" alt=""><br>默认逆时针旋转<br>如果是反方向旋转,我们直接使用转置矩阵/逆矩阵即可(转置矩阵和逆矩阵相等,正交矩阵)</p></blockquote></li></ul></li></ul><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p><strong>Linear Transforms = Matrices</strong></p><h2 id="Homogeneous-coordinates"><a href="#Homogeneous-coordinates" class="headerlink" title="Homogeneous coordinates"></a>Homogeneous coordinates</h2><p><strong>齐次坐标</strong></p><h3 id="Translation"><a href="#Translation" class="headerlink" title="Translation"></a>Translation</h3><blockquote><p>Cannot represented in matrix form<br><img src="https://pic.downk.cc/item/5eca45a9c2a9a83be5ef8760.png" alt=""><br>平移变换不是线性变换<br>但是我们不希望把它作为一个特殊例子对待<br>来找一种统一方法表达?(当然没有免费午餐,tradeoff)</p></blockquote><h3 id="Solution-homogenous-coordinates"><a href="#Solution-homogenous-coordinates" class="headerlink" title="Solution: homogenous coordinates"></a>Solution: homogenous coordinates</h3><p><strong>Add a third coordinate</strong></p><blockquote><p>2D point = transpose(x,y,<strong><em>1</em></strong>)<br>2D vector = transpose(x,y,<strong><em>0</em></strong>) #向量平移不变性<br><img src="https://pic.downk.cc/item/5eca48d4c2a9a83be5f2b48f.png" alt=""><br>why?<br>vector + vector = vector<br>point - point = vector<br>point + vector = point<br>point + point = <strong>??</strong><br>To emphasize this, we introduce<br>$$\begin{pmatrix}<br>x\<br>y\<br>z<br>\end{pmatrix} is\ 2D\ point<br>\begin{pmatrix}<br>x/w\<br>y/w\<br>1<br>\end{pmatrix}<br>where\ w!=0$$<br>在齐次坐标系中,两点的和便成了两点的中点</p></blockquote><h3 id="Affine-Transformations"><a href="#Affine-Transformations" class="headerlink" title="Affine Transformations"></a>Affine Transformations</h3><p>Affine map = linear map + translation<br>当我们用homogeneous coordinates表示仿射变换时,变换矩阵的最后一行永远是0,0,1</p><h3 id="Inverse-Transform"><a href="#Inverse-Transform" class="headerlink" title="Inverse Transform"></a>Inverse Transform</h3><p>逆变换和原矩阵在矩阵和几何意义上都是相反的</p><h2 id="Composite-Transform"><a href="#Composite-Transform" class="headerlink" title="Composite Transform"></a>Composite Transform</h2><ul><li>复杂的变换可以由简单变换组合得到</li><li>变换的顺序非常重要</li><li>矩阵乘法不满足交换律→变换顺序有关系</li><li>实际应用时,我们可以先将变换的矩阵进行提前计算,从而用一个矩阵代表非常复杂组合的变换</li></ul><blockquote><p>我们如何对于一个给定的点进行旋转?<br>先将图像平移到原点位置,然后进行旋转,再将其平移回去</p></blockquote><!-- rebuild by neat -->]]></content>
      
      
      <categories>
          
          <category> 课程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graphics </tag>
            
            <tag> lessons </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Markdown相关知识</title>
      <link href="/markdown.html"/>
      <url>/markdown.html</url>
      
        <content type="html"><![CDATA[<!-- build time:Fri Jan 01 2021 21:45:28 GMT+0800 (GMT+08:00) --><blockquote class="blockquote-center"><p>本文章主要介绍了markdown的相关语法和几个常用网站</p></blockquote><a id="more"></a><hr><h1 id="什么是Markdown"><a href="#什么是Markdown" class="headerlink" title="什么是Markdown"></a>什么是Markdown</h1><ul><li>Markdown是一种轻量化标记语言，它允许人们使用易读易写的纯文本格式编写文档。</li><li>用其编写的文档可以导出HTML、Word、图像和PDF等多种格式文档。</li><li>后缀名为.md/.markdown</li></ul><hr><h1 id="Markdown语法"><a href="#Markdown语法" class="headerlink" title="Markdown语法"></a>Markdown语法</h1><h2 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h2><p>Markdown标题有两种格式</p><pre><code>// = 和 - 标记语法格式一级标题=======二级标题-------// 事实上只需要一个 = / - 即可实现标题功能</code></pre><hr><pre><code>//使用 # 可以表示 1-6 级标题# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题</code></pre><h2 id="分割线"><a href="#分割线" class="headerlink" title="分割线"></a>分割线</h2><p>在一行中使用三个以上的星号、减号、下划线可以建立分割线</p><pre><code>*****-----_____//中间允许增加空格_ _ _  ___*   * *  ***</code></pre><h2 id="字操作"><a href="#字操作" class="headerlink" title="字操作"></a>字操作</h2><h3 id="字体"><a href="#字体" class="headerlink" title="字体"></a>字体</h3><p>Markdown 可以使用以下几种格式</p><pre><code>*斜体文本***粗体文本*****粗斜体文本***/*上述的 * 可以用 _ 代替但是由于LaTex也需要 _ 所以一般推荐能不用就不用在博客搭建过程中我已对_进行替换*/_斜体文本___粗体文本_____粗斜体文本___</code></pre><h3 id="删除线"><a href="#删除线" class="headerlink" title="删除线"></a>删除线</h3><p>段落文字添加删除线只需要在文字两端加入两个波浪线即可</p><pre><code>~~增加删除线的文字~~</code></pre><h3 id="下划线"><a href="#下划线" class="headerlink" title="下划线"></a>下划线</h3><p><u>下划线</u>通过HTML的标签实现</p><pre><code>&lt;u&gt;增加下划线的文本&lt;/u&gt;</code></pre><h2 id="Markdown-列表"><a href="#Markdown-列表" class="headerlink" title="Markdown 列表"></a>Markdown 列表</h2><h3 id="无序列表"><a href="#无序列表" class="headerlink" title="无序列表"></a>无序列表</h3><p>无序列表使用 * + - 作为列表标记</p><pre><code>* 第一项* 第二项+ 第一项+ 第二项- 第一项- 第二项</code></pre><h3 id="有序列表"><a href="#有序列表" class="headerlink" title="有序列表"></a>有序列表</h3><p>有序列表使用数字加上.号表示</p><pre><code>1.第一项2.第二项3.第三项</code></pre><h3 id="列表嵌套"><a href="#列表嵌套" class="headerlink" title="列表嵌套"></a>列表嵌套</h3><p>嵌套只需要在子列表的选项添加四个空格即可</p><pre><code>1.第一项    - 嵌套无序第一元素    - 嵌套无序第二元素2.第二项    - 嵌套无序第一元素    - 嵌套无序第二元素</code></pre><h2 id="区块"><a href="#区块" class="headerlink" title="区块"></a>区块</h2><p>区块引用时在段落开头使用 &gt; 符号</p><pre><code>&gt; 区块引用&gt; 后接空格&gt; 引用别人说的话</code></pre><hr><pre><code>&gt; 区块可嵌套&gt; &gt; 嵌套一层</code></pre><hr><pre><code>&gt; 区块中使用列表&gt; 1. 第一项&gt; 2. 第二项</code></pre><hr><pre><code>* 列表中使用区块需要在 &gt; 前添加缩进    &gt; 嵌套    &gt; &gt; 嵌套</code></pre><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>段落中的一个代码片段可以用反引号把它包起来 <code>printf()</code></p><pre><code>`printf()`</code></pre><hr><p>代码区块使用缩进,四个空格或一个制表符</p><pre><code>(Tab)代码段(Tab)code graph</code></pre><h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><pre><code>[链接名称](链接地址)&lt;链接地址&gt;</code></pre><p><a href="www.yqy1997.top">元气源的博客</a><br><a href="http://www.yqy1997.top">http://www.yqy1997.top</a></p><p>我们也可以通过变量设置链接</p><pre><code>此链接用link作为网址变量[yqy博客][link][link]: www.yqy1997.top</code></pre><p>此链接用link作为网址变量<a href="www.yqy1997.top">yqy博客</a></p><h2 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h2><pre><code>![图片替代文字](图片地址)</code></pre><p><img src="https://pic.downk.cc/item/5ec779d6c2a9a83be57da9bf.gif" alt="bqb"></p><h2 id="其他技巧"><a href="#其他技巧" class="headerlink" title="其他技巧"></a>其他技巧</h2><ul><li>支持HTML元素</li><li>转义显示特定符号使用反斜杠 \ 进行表示转义</li><li>公式/表格直接网站转换</li></ul><h1 id="Markdown-常用网站"><a href="#Markdown-常用网站" class="headerlink" title="Markdown 常用网站"></a>Markdown 常用网站</h1><ol><li><a href="https://www.tablesgenerator.com/markdown_tables" target="_blank" rel="noopener">markdown 表格生成</a><table><thead><tr><th align="center">测试表格</th><th align="center">A</th><th align="center">B</th><th align="center">C</th></tr></thead><tbody><tr><td align="center">甲</td><td align="center">1</td><td align="center">2</td><td align="center">3</td></tr><tr><td align="center">乙</td><td align="center">4</td><td align="center">5</td><td align="center">6</td></tr></tbody></table></li><li><a href="http://latex.codecogs.com/eqneditor/editor.php" target="_blank" rel="noopener">Latex在线生成</a><br>$$<br>\sum \frac{3}{5}<br>$$<br>//注意要用两端都要用两个美元符号进行包裹,需要使用使在blog头增加 mathjax: true<br>$$<br>\begin{vmatrix}1 &amp; 2 &amp; 3\ 4 &amp;5 &amp;6 \ 7&amp;8 &amp; 9\end{vmatrix}<br>$$</li></ol><!-- rebuild by neat -->]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> markdown </tag>
            
            <tag> tools </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HexoTagPlugin的使用技巧</title>
      <link href="/hexo_tag_plugin.html"/>
      <url>/hexo_tag_plugin.html</url>
      
        <content type="html"><![CDATA[<!-- build time:Fri Jan 01 2021 21:45:28 GMT+0800 (GMT+08:00) --><blockquote class="blockquote-center"><p>本文章介绍了几种Hexo中TagPlugin的使用技巧</p></blockquote><a id="more"></a><pre><code>阅读全文&lt;!-- more --&gt;</code></pre><h3 id="tag-plugin"><a href="#tag-plugin" class="headerlink" title="tag plugin"></a>tag plugin</h3><ul><li><blockquote class="blockquote-center"><p>世间所有的相遇，都是久别重逢</p></blockquote><p>使文本居中引用-Centered Quote</p></li><li><div class="note default"><p>default 提示块标签</p></div><div class="note primary"><p>primary 提示块标签</p></div><div class="note success"><p>success 提示块标签</p></div><div class="note info"><p>info 提示块标签</p></div><div class="note warning"><p>warning 提示块标签</p></div><div class="note danger"><p>danger 提示块标签</p></div><p>提示块-Note</p></li><li><span class="label default">默认</span> <span class="label primary">主要</span> <span class="label success">成功</span> <span class="label info">信息</span> <span class="label warning">警告</span> <span class="label danger">危险</span> <span class="label success">这是成功的信息</span><p>标签-Label</p></li><li><div class="tabs" id="tab"><ul class="nav-tabs"><li class="tab active"><a href="#tab-1">选项卡1</a></li><li class="tab"><a href="#tab-2">选项卡2</a></li><li class="tab"><a href="#tab-3">A</a></li></ul><div class="tab-content"><div class="tab-pane active" id="tab-1"><p><strong>选项卡 1</strong></p></div><div class="tab-pane" id="tab-2"><p><strong>选项卡 2</strong></p></div><div class="tab-pane" id="tab-3"><p><strong>选项卡 3</strong> 名字为A</p></div></div></div><p>选项卡-Tabs</p></li></ul><ul><li>% button url, text, icon [class], [title] % ###左右加花括号<ul><li>url 绝对/相对URL</li><li>text 按钮文字</li><li>icon FontAwesome图标名称</li><li>clasee FontAwesome 类：fa-fw | fa-lg | fa-2x | fa-3x | fa-4x | fa-5X ，可选参数</li><li>title 鼠标悬停时的工具提示<div><a class="btn" href="http://www.yqy1997.top/" title="go back to main page"><i class="fa fa-home fa-fw"></i>首页</a></div>/n 例子<div class="text-center"><div><a class="btn" href="http://www.yqy1997.top/" title="这是小丁的个人博客首页"><i class="fa fa-home fa-fw"></i>首页</a> <a class="btn" href="http://www.yqy1997.top/" title="豆瓣电影"><i class="fa fa-film fa-fw"></i>观影</a> <a class="btn" href="http://www.yqy1997.top/" title="豆瓣读书"><i class="fa fa-book fa-fw"></i>阅读</a></div></div>/n 居中</li></ul></li></ul><!-- rebuild by neat -->]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> plugin </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>待整理区域</title>
      <link href="/messy.html"/>
      <url>/messy.html</url>
      
        <content type="html"><![CDATA[<!-- build time:Fri Jan 01 2021 21:45:28 GMT+0800 (GMT+08:00) --><a id="more"></a><p>$$<br>\sum \frac{3}{5}<br>$$</p><p><strong>asdfkljg</strong></p><p><a href="https://www.mathcha.io/editor" target="_blank" rel="noopener">https://www.mathcha.io/editor</a> 数学公式编辑器,比Latex还好用</p><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><pre><code>def adef bdef c</code></pre><h2 id="https-copytranslator-github-io"><a href="#https-copytranslator-github-io" class="headerlink" title="https://copytranslator.github.io/"></a><a href="https://copytranslator.github.io/" target="_blank" rel="noopener">https://copytranslator.github.io/</a></h2><h2 id="https-www-superbed-cn-聚合图床"><a href="#https-www-superbed-cn-聚合图床" class="headerlink" title="https://www.superbed.cn/  聚合图床"></a><a href="https://www.superbed.cn/" target="_blank" rel="noopener">https://www.superbed.cn/</a> <strong>聚合图床</strong></h2><h2 id="https-leancloud-cn-dashboard-applist-html-apps-leancloud-管理评论-计数信息-密码分大小写"><a href="#https-leancloud-cn-dashboard-applist-html-apps-leancloud-管理评论-计数信息-密码分大小写" class="headerlink" title="https://leancloud.cn/dashboard/applist.html#/apps leancloud 管理评论 计数信息 密码分大小写"></a><a href="https://leancloud.cn/dashboard/applist.html#/apps" target="_blank" rel="noopener">https://leancloud.cn/dashboard/applist.html#/apps</a> leancloud 管理评论 计数信息 密码分大小写</h2><h2 id="https-search-google-com-search-console-sitemaps-resource-id-http-3A-2F-2Fwww-yqy1997-top-2F-谷歌站点地图"><a href="#https-search-google-com-search-console-sitemaps-resource-id-http-3A-2F-2Fwww-yqy1997-top-2F-谷歌站点地图" class="headerlink" title="https://search.google.com/search-console/sitemaps?resource_id=http%3A%2F%2Fwww.yqy1997.top%2F 谷歌站点地图"></a><a href="https://search.google.com/search-console/sitemaps?resource_id=http%3A%2F%2Fwww.yqy1997.top%2F" target="_blank" rel="noopener">https://search.google.com/search-console/sitemaps?resource_id=http%3A%2F%2Fwww.yqy1997.top%2F</a> 谷歌站点地图</h2><h2 id="https-ziyuan-baidu-com-linksubmit-index-site-http-www-yqy1997-top-百度站点地图"><a href="#https-ziyuan-baidu-com-linksubmit-index-site-http-www-yqy1997-top-百度站点地图" class="headerlink" title="https://ziyuan.baidu.com/linksubmit/index?site=http://www.yqy1997.top/ 百度站点地图"></a><a href="https://ziyuan.baidu.com/linksubmit/index?site=http://www.yqy1997.top/" target="_blank" rel="noopener">https://ziyuan.baidu.com/linksubmit/index?site=http://www.yqy1997.top/</a> 百度站点地图</h2><h2 id="黄金神威"><a href="#黄金神威" class="headerlink" title="黄金神威"></a>黄金神威</h2><h2 id="数字图像处理"><a href="#数字图像处理" class="headerlink" title="数字图像处理"></a>数字图像处理</h2><h3 id="1、用conda创建Python虚拟环境（在conda-prompt环境下完成）"><a href="#1、用conda创建Python虚拟环境（在conda-prompt环境下完成）" class="headerlink" title="1、用conda创建Python虚拟环境（在conda prompt环境下完成）"></a>1、用conda创建Python虚拟环境（在conda prompt环境下完成）</h3><p><code>conda create -n environment_name python=X.X</code><br>(注：该命令只适用于Windows环境；“environment_name”是要创建的环境名；“python=X.X”是选择的Python版本)</p><h3 id="2、激活虚拟环境（在conda-prompt环境下完成）"><a href="#2、激活虚拟环境（在conda-prompt环境下完成）" class="headerlink" title="2、激活虚拟环境（在conda prompt环境下完成）"></a>2、激活虚拟环境（在conda prompt环境下完成）</h3><p><code>activate your_env_name</code><br>Windows: activate your_env_name(虚拟环境名称)</p><h3 id="3、给虚拟环境安装外部包"><a href="#3、给虚拟环境安装外部包" class="headerlink" title="3、给虚拟环境安装外部包"></a>3、给虚拟环境安装外部包</h3><p><code>conda install -n your_env_name [package]</code><br>例如: conda install -n tensorflow pandas</p><h3 id="4、查看已有的环境-当前已激活的环境会显示一个星号"><a href="#4、查看已有的环境-当前已激活的环境会显示一个星号" class="headerlink" title="4、查看已有的环境(当前已激活的环境会显示一个星号)"></a>4、查看已有的环境(当前已激活的环境会显示一个星号)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda info -e</span><br></pre></td></tr></table></figure><h3 id="5、删除一个已有的虚拟环境"><a href="#5、删除一个已有的虚拟环境" class="headerlink" title="5、删除一个已有的虚拟环境"></a>5、删除一个已有的虚拟环境</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda remove --name your_env_name --all</span><br></pre></td></tr></table></figure><h3 id="6、查看pip的安装目录"><a href="#6、查看pip的安装目录" class="headerlink" title="6、查看pip的安装目录"></a>6、查看pip的安装目录</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip list</span><br></pre></td></tr></table></figure><p>7、删除已经安装的模块<br><code>pip uninstall **</code><br>(例如：pip uninstall numpy)</p><!-- rebuild by neat -->]]></content>
      
      
      <categories>
          
          <category> testing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Test </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
